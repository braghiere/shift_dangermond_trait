{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3efab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets for all times...\n",
      "Processing data for time: 00\n",
      "PFT 1: Average chl value: 46.729957580566406, Standard Deviation: 24.14640235900879\n",
      "PFT 2: Average chl value: 41.99604415893555, Standard Deviation: 23.10335922241211\n",
      "PFT 3: Average chl value: 61.09103012084961, Standard Deviation: 21.684953689575195\n",
      "PFT 1: Average lai value: 3.1625101566314697, Standard Deviation: 4.1916093826293945\n",
      "PFT 2: Average lai value: 2.9527974128723145, Standard Deviation: 4.051224231719971\n",
      "PFT 3: Average lai value: 5.522914886474609, Standard Deviation: 5.532774925231934\n",
      "PFT 1: Average lma value: 79.47981262207031, Standard Deviation: 101.08904266357422\n",
      "PFT 2: Average lma value: 68.23155212402344, Standard Deviation: 93.9632797241211\n",
      "PFT 3: Average lma value: 150.521728515625, Standard Deviation: 136.132080078125\n",
      "Processing data for time: 01\n",
      "PFT 1: Average chl value: 43.979766845703125, Standard Deviation: 24.082256317138672\n",
      "PFT 2: Average chl value: 39.70149612426758, Standard Deviation: 22.693452835083008\n",
      "PFT 3: Average chl value: 59.3845100402832, Standard Deviation: 22.051124572753906\n",
      "PFT 1: Average lai value: 2.801231861114502, Standard Deviation: 3.8114562034606934\n",
      "PFT 2: Average lai value: 2.6050188541412354, Standard Deviation: 3.6731910705566406\n",
      "PFT 3: Average lai value: 4.929548740386963, Standard Deviation: 4.960460186004639\n",
      "PFT 1: Average lma value: 67.49840545654297, Standard Deviation: 89.6330795288086\n",
      "PFT 2: Average lma value: 57.78425979614258, Standard Deviation: 83.68087768554688\n",
      "PFT 3: Average lma value: 130.94979858398438, Standard Deviation: 121.99935913085938\n",
      "Processing data for time: 02\n",
      "PFT 1: Average chl value: 44.33891677856445, Standard Deviation: 23.780895233154297\n",
      "PFT 2: Average chl value: 38.91999816894531, Standard Deviation: 22.307130813598633\n",
      "PFT 3: Average chl value: 58.3569221496582, Standard Deviation: 21.672563552856445\n",
      "PFT 1: Average lai value: 2.861719846725464, Standard Deviation: 3.898144483566284\n",
      "PFT 2: Average lai value: 2.580091714859009, Standard Deviation: 3.7050416469573975\n",
      "PFT 3: Average lai value: 5.027500629425049, Standard Deviation: 5.013463497161865\n",
      "PFT 1: Average lma value: 71.91690826416016, Standard Deviation: 89.48117065429688\n",
      "PFT 2: Average lma value: 60.5725212097168, Standard Deviation: 80.76006317138672\n",
      "PFT 3: Average lma value: 130.0396270751953, Standard Deviation: 116.09423828125\n",
      "Processing data for time: 03\n",
      "PFT 1: Average chl value: 35.97517395019531, Standard Deviation: 22.465438842773438\n",
      "PFT 2: Average chl value: 32.30778884887695, Standard Deviation: 20.475276947021484\n",
      "PFT 3: Average chl value: 52.737125396728516, Standard Deviation: 22.575523376464844\n",
      "PFT 1: Average lai value: 2.337899684906006, Standard Deviation: 3.1660783290863037\n",
      "PFT 2: Average lai value: 2.2149858474731445, Standard Deviation: 3.1408309936523438\n",
      "PFT 3: Average lai value: 4.379950523376465, Standard Deviation: 4.262785911560059\n",
      "PFT 1: Average lma value: 55.453460693359375, Standard Deviation: 69.287353515625\n",
      "PFT 2: Average lma value: 49.15327453613281, Standard Deviation: 64.08201599121094\n",
      "PFT 3: Average lma value: 109.6851577758789, Standard Deviation: 96.10921478271484\n",
      "Processing data for time: 04\n",
      "PFT 1: Average chl value: 44.33628463745117, Standard Deviation: 23.3028564453125\n",
      "PFT 2: Average chl value: 39.12870788574219, Standard Deviation: 22.04659080505371\n",
      "PFT 3: Average chl value: 57.25511932373047, Standard Deviation: 21.361536026000977\n",
      "PFT 1: Average lai value: 2.5401611328125, Standard Deviation: 3.725193500518799\n",
      "PFT 2: Average lai value: 2.345837116241455, Standard Deviation: 3.6323347091674805\n",
      "PFT 3: Average lai value: 4.758341312408447, Standard Deviation: 4.845849514007568\n",
      "PFT 1: Average lma value: 68.76408386230469, Standard Deviation: 82.51746368408203\n",
      "PFT 2: Average lma value: 59.057281494140625, Standard Deviation: 73.02793884277344\n",
      "PFT 3: Average lma value: 117.93714141845703, Standard Deviation: 104.75072479248047\n",
      "Processing data for time: 05\n",
      "PFT 1: Average chl value: 33.892906188964844, Standard Deviation: 20.589265823364258\n",
      "PFT 2: Average chl value: 29.334959030151367, Standard Deviation: 18.320785522460938\n",
      "PFT 3: Average chl value: 51.1032600402832, Standard Deviation: 21.552085876464844\n",
      "PFT 1: Average lai value: 2.0008904933929443, Standard Deviation: 2.5605907440185547\n",
      "PFT 2: Average lai value: 1.9591240882873535, Standard Deviation: 2.7923312187194824\n",
      "PFT 3: Average lai value: 3.8213491439819336, Standard Deviation: 3.4363958835601807\n",
      "PFT 1: Average lma value: 51.799346923828125, Standard Deviation: 57.81343460083008\n",
      "PFT 2: Average lma value: 47.06357955932617, Standard Deviation: 58.8418083190918\n",
      "PFT 3: Average lma value: 98.7283935546875, Standard Deviation: 78.30760955810547\n",
      "Processing data for time: 06\n",
      "PFT 1: Average chl value: 29.26422119140625, Standard Deviation: 20.33661651611328\n",
      "PFT 2: Average chl value: 24.155784606933594, Standard Deviation: 17.312219619750977\n",
      "PFT 3: Average chl value: 45.61111831665039, Standard Deviation: 22.502614974975586\n",
      "PFT 1: Average lai value: 1.7186317443847656, Standard Deviation: 2.4869611263275146\n",
      "PFT 2: Average lai value: 1.5307230949401855, Standard Deviation: 2.3183906078338623\n",
      "PFT 3: Average lai value: 3.257086753845215, Standard Deviation: 3.055248260498047\n",
      "PFT 1: Average lma value: 46.42193603515625, Standard Deviation: 57.7116584777832\n",
      "PFT 2: Average lma value: 39.21342468261719, Standard Deviation: 50.284244537353516\n",
      "PFT 3: Average lma value: 87.9096450805664, Standard Deviation: 71.20423126220703\n",
      "Processing data for time: 07\n",
      "PFT 1: Average chl value: 24.52532196044922, Standard Deviation: 17.936996459960938\n",
      "PFT 2: Average chl value: 20.45149803161621, Standard Deviation: 15.489215850830078\n",
      "PFT 3: Average chl value: 38.418060302734375, Standard Deviation: 20.700109481811523\n",
      "PFT 1: Average lai value: 1.2239078283309937, Standard Deviation: 1.7350810766220093\n",
      "PFT 2: Average lai value: 1.116944432258606, Standard Deviation: 1.801390528678894\n",
      "PFT 3: Average lai value: 2.3476502895355225, Standard Deviation: 2.172451972961426\n",
      "PFT 1: Average lma value: 39.245941162109375, Standard Deviation: 46.14424514770508\n",
      "PFT 2: Average lma value: 34.317325592041016, Standard Deviation: 42.962066650390625\n",
      "PFT 3: Average lma value: 73.9761734008789, Standard Deviation: 57.173919677734375\n",
      "Processing data for time: 08\n",
      "PFT 1: Average chl value: 24.886810302734375, Standard Deviation: 17.368656158447266\n",
      "PFT 2: Average chl value: 20.953990936279297, Standard Deviation: 15.787999153137207\n",
      "PFT 3: Average chl value: 37.59053421020508, Standard Deviation: 19.639442443847656\n",
      "PFT 1: Average lai value: 1.2465170621871948, Standard Deviation: 1.8182626962661743\n",
      "PFT 2: Average lai value: 1.2171220779418945, Standard Deviation: 2.294240713119507\n",
      "PFT 3: Average lai value: 2.3000566959381104, Standard Deviation: 2.1096510887145996\n",
      "PFT 1: Average lma value: 39.096038818359375, Standard Deviation: 47.36128234863281\n",
      "PFT 2: Average lma value: 35.685386657714844, Standard Deviation: 53.761871337890625\n",
      "PFT 3: Average lma value: 70.03475952148438, Standard Deviation: 54.929630279541016\n",
      "Processing data for time: 09\n",
      "PFT 1: Average chl value: 18.28829002380371, Standard Deviation: 15.582550048828125\n",
      "PFT 2: Average chl value: 14.814322471618652, Standard Deviation: 12.176765441894531\n",
      "PFT 3: Average chl value: 31.746946334838867, Standard Deviation: 19.475624084472656\n",
      "PFT 1: Average lai value: 0.8554477095603943, Standard Deviation: 1.3896745443344116\n",
      "PFT 2: Average lai value: 0.7296227216720581, Standard Deviation: 1.4056288003921509\n",
      "PFT 3: Average lai value: 1.8511911630630493, Standard Deviation: 1.7509791851043701\n",
      "PFT 1: Average lma value: 29.83783531188965, Standard Deviation: 40.29806900024414\n",
      "PFT 2: Average lma value: 25.767982482910156, Standard Deviation: 38.381893157958984\n",
      "PFT 3: Average lma value: 61.663578033447266, Standard Deviation: 51.33980941772461\n",
      "Processing data for time: 10\n",
      "PFT 1: Average chl value: 17.539751052856445, Standard Deviation: 15.556224822998047\n",
      "PFT 2: Average chl value: 12.771330833435059, Standard Deviation: 12.414155006408691\n",
      "PFT 3: Average chl value: 29.05889320373535, Standard Deviation: 18.78983497619629\n",
      "PFT 1: Average lai value: 0.86321622133255, Standard Deviation: 1.6881896257400513\n",
      "PFT 2: Average lai value: 0.6527736186981201, Standard Deviation: 1.5737149715423584\n",
      "PFT 3: Average lai value: 1.6189684867858887, Standard Deviation: 1.591029405593872\n",
      "PFT 1: Average lma value: 30.880285263061523, Standard Deviation: 44.47759246826172\n",
      "PFT 2: Average lma value: 24.227218627929688, Standard Deviation: 40.6201171875\n",
      "PFT 3: Average lma value: 58.532649993896484, Standard Deviation: 50.22504425048828\n",
      "Processing data for time: 11\n",
      "PFT 1: Average chl value: 14.704618453979492, Standard Deviation: 13.157190322875977\n",
      "PFT 2: Average chl value: 10.984109878540039, Standard Deviation: 10.957596778869629\n",
      "PFT 3: Average chl value: 25.19135093688965, Standard Deviation: 17.3702392578125\n",
      "PFT 1: Average lai value: 0.6348601579666138, Standard Deviation: 1.0916554927825928\n",
      "PFT 2: Average lai value: 0.5095308423042297, Standard Deviation: 1.0565277338027954\n",
      "PFT 3: Average lai value: 1.433714509010315, Standard Deviation: 1.4804470539093018\n",
      "PFT 1: Average lma value: 24.397974014282227, Standard Deviation: 34.0716667175293\n",
      "PFT 2: Average lma value: 20.431838989257812, Standard Deviation: 31.01211929321289\n",
      "PFT 3: Average lma value: 51.193626403808594, Standard Deviation: 46.93000411987305\n",
      "Processing data for time: 12\n",
      "PFT 1: Average chl value: 19.905723571777344, Standard Deviation: 15.388687133789062\n",
      "PFT 2: Average chl value: 15.963467597961426, Standard Deviation: 14.426827430725098\n",
      "PFT 3: Average chl value: 31.564367294311523, Standard Deviation: 18.594419479370117\n",
      "PFT 1: Average lai value: 0.7717059850692749, Standard Deviation: 1.2931026220321655\n",
      "PFT 2: Average lai value: 0.6322526931762695, Standard Deviation: 1.3178621530532837\n",
      "PFT 3: Average lai value: 1.7237370014190674, Standard Deviation: 1.7811442613601685\n",
      "PFT 1: Average lma value: 29.371334075927734, Standard Deviation: 39.01276397705078\n",
      "PFT 2: Average lma value: 24.48192024230957, Standard Deviation: 36.93418502807617\n",
      "PFT 3: Average lma value: 59.50562286376953, Standard Deviation: 50.9705924987793\n",
      "Data processing and saving completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Define the range of times from 00 to 12\n",
    "times = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "# Given dates\n",
    "dates = [\"2022-02-24T00:00:00.000000\", \"2022-02-28T00:00:00.000000\", \"2022-03-08T00:00:00.000000\",\n",
    "         \"2022-03-16T00:00:00.000000\", \"2022-03-22T00:00:00.000000\", \"2022-04-05T00:00:00.000000\",\n",
    "         \"2022-04-12T00:00:00.000000\", \"2022-04-20T00:00:00.000000\", \"2022-04-29T00:00:00.000000\",\n",
    "         \"2022-05-03T00:00:00.000000\", \"2022-05-11T00:00:00.000000\", \"2022-05-17T00:00:00.000000\",\n",
    "         \"2022-05-29T00:00:00.000000\"]\n",
    "\n",
    "# Extract dates without times\n",
    "dates_without_times = [date.split('T')[0] for date in dates]\n",
    "\n",
    "# Load PFT dataset\n",
    "pft_ds = xr.open_dataset('/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/California_Vegetation_WHRTYPE_Dangermond/output_latlon.nc')\n",
    "\n",
    "# Informative message: Loading datasets for all times\n",
    "print(f'Loading datasets for all times...')\n",
    "\n",
    "# Load the combined datasets for chl, lai, and lma\n",
    "chl_ds = xr.open_dataset('/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/chl_aviris_dangermond_clima_fit_reg.nc')\n",
    "lai_ds = xr.open_dataset('/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lwc_aviris_dangermond_clima_fit_reg.nc')\n",
    "lma_ds = xr.open_dataset('/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lma_aviris_dangermond_clima_fit_reg.nc')\n",
    "\n",
    "# Extract chl, lai, and lma values and PFT data\n",
    "chl_values = chl_ds['chl'].values\n",
    "lai_values = lai_ds['lwc'].values\n",
    "lma_values = lma_ds['lma'].values * 10000   # Convert lma values to g.m^-2\n",
    "pft_values = pft_ds['Band1'].values  # Assuming PFT values are stored in Band1 variable\n",
    "\n",
    "# Define PFT categories (2, 3, 4)\n",
    "pft_categories = [2, 3, 4]\n",
    "\n",
    "# Create a mask for PFT categories\n",
    "pft_mask = np.isin(pft_values, pft_categories)\n",
    "\n",
    "# Initialize arrays to store new data\n",
    "new_chl_values = np.zeros_like(chl_values)\n",
    "new_std_chl_values = np.zeros_like(chl_values)\n",
    "new_lai_values = np.zeros_like(lai_values)\n",
    "new_std_lai_values = np.zeros_like(lai_values)\n",
    "new_lma_values = np.zeros_like(lma_values)\n",
    "new_std_lma_values = np.zeros_like(lma_values)\n",
    "\n",
    "# Loop over times\n",
    "for time_index, time in enumerate(times):\n",
    "    # Informative message: Loading datasets for the current time\n",
    "    print(f'Processing data for time: {time}')\n",
    "    \n",
    "    # Extract chl, lai, lma values for the current time\n",
    "    chl_values_time = chl_values[time_index, :, :]\n",
    "    lai_values_time = lai_values[time_index, :, :]\n",
    "    lma_values_time = lma_values[time_index, :, :]\n",
    "    \n",
    "    # Ensure values and pft_mask have the same shape\n",
    "    masked_chl_values = np.ma.masked_where(~pft_mask, chl_values_time)\n",
    "    masked_lai_values = np.ma.masked_where(~pft_mask, lai_values_time)\n",
    "    masked_lma_values = np.ma.masked_where(~pft_mask, lma_values_time)\n",
    "    \n",
    "    # Calculate average and std values per PFT for chl, lai, and lma\n",
    "    average_chl_per_pft = []\n",
    "    std_chl_per_pft = []\n",
    "    average_lai_per_pft = []\n",
    "    std_lai_per_pft = []\n",
    "    average_lma_per_pft = []\n",
    "    std_lma_per_pft = []\n",
    "\n",
    "    for pft_category in pft_categories:\n",
    "        # chl\n",
    "        pft_chl_values = masked_chl_values[pft_values == pft_category]\n",
    "        average_chl = np.nanmean(pft_chl_values)\n",
    "        std_chl = np.nanstd(pft_chl_values)\n",
    "        average_chl_per_pft.append(average_chl)\n",
    "        std_chl_per_pft.append(std_chl)\n",
    "        \n",
    "        # lai\n",
    "        pft_lai_values = masked_lai_values[pft_values == pft_category]\n",
    "        average_lai = np.nanmean(pft_lai_values)\n",
    "        std_lai = np.nanstd(pft_lai_values)\n",
    "        average_lai_per_pft.append(average_lai)\n",
    "        std_lai_per_pft.append(std_lai)\n",
    "        \n",
    "        # lma\n",
    "        pft_lma_values = masked_lma_values[pft_values == pft_category]\n",
    "        pft_lma_values = pft_lma_values[(~np.isnan(pft_lma_values)) & (pft_lma_values != 0)]\n",
    "        average_lma = np.nanmean(pft_lma_values)\n",
    "        std_lma = np.nanstd(pft_lma_values)\n",
    "        average_lma_per_pft.append(average_lma)\n",
    "        std_lma_per_pft.append(std_lma)\n",
    "    \n",
    "    # Print average and standard deviation values per PFT for chl, lai, and lma\n",
    "    for idx, (avg_chl, std_chl) in enumerate(zip(average_chl_per_pft, std_chl_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average chl value: {avg_chl}, Standard Deviation: {std_chl}')\n",
    "    for idx, (avg_lai, std_lai) in enumerate(zip(average_lai_per_pft, std_lai_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average lai value: {avg_lai}, Standard Deviation: {std_lai}')\n",
    "    for idx, (avg_lma, std_lma) in enumerate(zip(average_lma_per_pft, std_lma_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx]-1}: Average lma value: {avg_lma}, Standard Deviation: {std_lma}')\n",
    "\n",
    "    # Assign average and std values to new arrays\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)\n",
    "        new_chl_values[time_index, mask] = average_chl_per_pft[idx]\n",
    "        new_std_chl_values[time_index, mask] = std_chl_per_pft[idx]\n",
    "        new_lai_values[time_index, mask] = average_lai_per_pft[idx]\n",
    "        new_std_lai_values[time_index, mask] = std_lai_per_pft[idx]\n",
    "        new_lma_values[time_index, mask] = average_lma_per_pft[idx]\n",
    "        new_std_lma_values[time_index, mask] = std_lma_per_pft[idx]\n",
    "\n",
    "    # Plotting figures for each trait\n",
    "\n",
    "    # Creating plots for all PFTs for chl\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size\n",
    "    colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)\n",
    "        \n",
    "        # Extract chl values for the current PFT category\n",
    "        chl_for_pft = masked_chl_values[mask].compressed()\n",
    "        avg_chl = average_chl_per_pft[idx]\n",
    "        std_chl = std_chl_per_pft[idx]\n",
    "\n",
    "        # Create a histogram for chl values with transparency\n",
    "        plt.hist(chl_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "\n",
    "        # Add a vertical line for the average\n",
    "        plt.axvline(avg_chl, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Prepare text for the legend\n",
    "        avg_std_text = f'{avg_chl:.2f} ± {std_chl:.2f}'\n",
    "        legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "    plt.title(f'Combined CHL Distribution ({dates_without_times[time_index]})', fontsize=18)\n",
    "    plt.xlabel(r'CHL Value ($\\mu$g.cm$^{-2}$)', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.ylim(0, 0.3)  # Set y-axis limits\n",
    "    plt.xlim(0, 90)  # Set y-axis limits\n",
    "    plt.legend(legend_labels, fontsize=14)  # Increase legend fontsize\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick label fontsize\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick label fontsize\n",
    "\n",
    "    # Save the combined plot as a PNG file\n",
    "    plt.savefig(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/combined_chl_histogram_time_{time}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Creating plots for all PFTs for lai\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size\n",
    "    colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)\n",
    "        \n",
    "        # Extract lai values for the current PFT category\n",
    "        lai_for_pft = masked_lai_values[mask].compressed()\n",
    "        avg_lai = average_lai_per_pft[idx]\n",
    "        std_lai = std_lai_per_pft[idx]\n",
    "\n",
    "        # Create a histogram for lai values with transparency\n",
    "        plt.hist(lai_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "\n",
    "        # Add a vertical line for the average\n",
    "        plt.axvline(avg_lai, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Prepare text for the legend\n",
    "        avg_std_text = f'{avg_lai:.2f} ± {std_lai:.2f}'\n",
    "        legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "    plt.title(f'Combined LWC Distribution ({dates_without_times[time_index]})', fontsize=18)\n",
    "    plt.xlabel(r'LWC Value (mol.m$^{-2}$)', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.ylim(0, 1.0)  # Set y-axis limits\n",
    "    plt.xlim(0, 20)  # Set y-axis limits\n",
    "    plt.legend(legend_labels, fontsize=14)  # Increase legend fontsize\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick label fontsize\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick label fontsize\n",
    "\n",
    "    # Save the combined plot as a PNG file\n",
    "    plt.savefig(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/combined_lwc_histogram_time_{time}.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Creating plots for all PFTs for lma\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size\n",
    "    colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)\n",
    "        \n",
    "        # Extract lma values for the current PFT category\n",
    "        lma_for_pft = masked_lma_values[mask].compressed()\n",
    "        avg_lma = average_lma_per_pft[idx]\n",
    "        std_lma = std_lma_per_pft[idx]\n",
    "\n",
    "        # Create a histogram for lma values with transparency\n",
    "        plt.hist(lma_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "\n",
    "        # Add a vertical line for the average\n",
    "        plt.axvline(avg_lma, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Prepare text for the legend\n",
    "        avg_std_text = f'{avg_lma:.2e} ± {std_lma:.2e}'\n",
    "        legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "    plt.title(f'Combined LMA Distribution ({dates_without_times[time_index]})', fontsize=18)\n",
    "    plt.xlabel(r'LMA Value (g.cm$^{-2}$)', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.ylim(0, 1.0)  # Set y-axis limits\n",
    "    plt.xlim(0, 500)  # Set y-axis limits\n",
    "    plt.legend(legend_labels, fontsize=14)  # Increase legend fontsize\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick label fontsize\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick label fontsize\n",
    "\n",
    "    # Save the combined plot as a PNG file\n",
    "    plt.savefig(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/combined_lma_histogram_time_{time}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Replace zeros by NaN in new maps\n",
    "new_chl_values = np.where(new_chl_values != 0, new_chl_values, np.nan)\n",
    "new_std_chl_values = np.where(new_std_chl_values != 0, new_std_chl_values, np.nan)\n",
    "new_lai_values = np.where(new_lai_values != 0, new_lai_values, np.nan)\n",
    "new_std_lai_values = np.where(new_std_lai_values != 0, new_std_lai_values, np.nan)\n",
    "new_lma_values = np.where(new_lma_values != 0, new_lma_values, np.nan)\n",
    "new_std_lma_values = np.where(new_std_lma_values != 0, new_std_lma_values, np.nan)\n",
    "\n",
    "# Save the new datasets to NetCDF files\n",
    "new_chl_ds = xr.Dataset({\n",
    "    'chl': (('time', 'lat', 'lon'), new_chl_values),\n",
    "    'std_chl': (('time', 'lat', 'lon'), new_std_chl_values)},\n",
    "    coords={'time': chl_ds['time'], 'lat': chl_ds['lat'], 'lon': chl_ds['lon']})\n",
    "new_chl_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_chl_aviris_dangermond_clima_fit.nc')\n",
    "\n",
    "new_lai_ds = xr.Dataset({\n",
    "    'lwc': (('time', 'lat', 'lon'), new_lai_values),\n",
    "    'std_lwc': (('time', 'lat', 'lon'), new_std_lai_values)},\n",
    "    coords={'time': lai_ds['time'], 'lat': lai_ds['lat'], 'lon': lai_ds['lon']})\n",
    "new_lai_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lwc_aviris_dangermond_clima_fit.nc')\n",
    "\n",
    "new_lma_ds = xr.Dataset({\n",
    "    'lma': (('time', 'lat', 'lon'), new_lma_values),\n",
    "    'std_lma': (('time', 'lat', 'lon'), new_std_lma_values)},\n",
    "    coords={'time': lma_ds['time'], 'lat': lma_ds['lat'], 'lon': lma_ds['lon']})\n",
    "new_lma_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lma_aviris_dangermond_clima_fit.nc')\n",
    "\n",
    "# Informative message: Data processing and saving completed\n",
    "print(f'Data processing and saving completed.\\n')\n",
    "\n",
    "# Close the opened datasets\n",
    "chl_ds.close()\n",
    "lai_ds.close()\n",
    "lma_ds.close()\n",
    "pft_ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aac025e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets for all times...\n",
      "Processing data for time: 00\n",
      "PFT 1: Average chl value: 0.0037749402690678835, Standard Deviation: 0.004777900874614716\n",
      "PFT 2: Average chl value: 0.003240694059059024, Standard Deviation: 0.00432511605322361\n",
      "PFT 3: Average chl value: 0.007597974967211485, Standard Deviation: 0.0058870441280305386\n",
      "PFT 1: Average lai value: 0.004173042252659798, Standard Deviation: 0.007828260771930218\n",
      "PFT 2: Average lai value: 0.0035824610386043787, Standard Deviation: 0.007319921627640724\n",
      "PFT 3: Average lai value: 0.007454197853803635, Standard Deviation: 0.010692716576159\n",
      "Processing data for time: 01\n",
      "PFT 1: Average chl value: 0.003352547064423561, Standard Deviation: 0.00452774902805686\n",
      "PFT 2: Average chl value: 0.002853008219972253, Standard Deviation: 0.004072333686053753\n",
      "PFT 3: Average chl value: 0.00705363554880023, Standard Deviation: 0.0057800025679171085\n",
      "PFT 1: Average lai value: 0.003397292923182249, Standard Deviation: 0.006799566093832254\n",
      "PFT 2: Average lai value: 0.002925417385995388, Standard Deviation: 0.006350627169013023\n",
      "PFT 3: Average lai value: 0.006041343789547682, Standard Deviation: 0.009441041387617588\n",
      "Processing data for time: 02\n",
      "PFT 1: Average chl value: 0.0038975533097982407, Standard Deviation: 0.0047516063787043095\n",
      "PFT 2: Average chl value: 0.0033831472974270582, Standard Deviation: 0.004306357353925705\n",
      "PFT 3: Average chl value: 0.0076296767219901085, Standard Deviation: 0.005794881843030453\n",
      "PFT 1: Average lai value: 0.0032941377721726894, Standard Deviation: 0.006763093173503876\n",
      "PFT 2: Average lai value: 0.002674104878678918, Standard Deviation: 0.005923988297581673\n",
      "PFT 3: Average lai value: 0.005374286323785782, Standard Deviation: 0.008912402205169201\n",
      "Processing data for time: 03\n",
      "PFT 1: Average chl value: 0.0036316080950200558, Standard Deviation: 0.004560751374810934\n",
      "PFT 2: Average chl value: 0.0031995773315429688, Standard Deviation: 0.004158773459494114\n",
      "PFT 3: Average chl value: 0.007487156894057989, Standard Deviation: 0.005719374865293503\n",
      "PFT 1: Average lai value: 0.0019137379713356495, Standard Deviation: 0.004488872364163399\n",
      "PFT 2: Average lai value: 0.0017157497350126505, Standard Deviation: 0.004157334566116333\n",
      "PFT 3: Average lai value: 0.00348135968670249, Standard Deviation: 0.0067891874350607395\n",
      "Processing data for time: 04\n",
      "PFT 1: Average chl value: 0.003882898483425379, Standard Deviation: 0.004586655180901289\n",
      "PFT 2: Average chl value: 0.003580323653295636, Standard Deviation: 0.0043063415214419365\n",
      "PFT 3: Average chl value: 0.007419775240123272, Standard Deviation: 0.005636432208120823\n",
      "PFT 1: Average lai value: 0.0029935103375464678, Standard Deviation: 0.006329220719635487\n",
      "PFT 2: Average lai value: 0.002325404202565551, Standard Deviation: 0.005254601128399372\n",
      "PFT 3: Average lai value: 0.004373938776552677, Standard Deviation: 0.007964866235852242\n",
      "Processing data for time: 05\n",
      "PFT 1: Average chl value: 0.003673505736514926, Standard Deviation: 0.0043962085619568825\n",
      "PFT 2: Average chl value: 0.0033783316612243652, Standard Deviation: 0.004091169219464064\n",
      "PFT 3: Average chl value: 0.007430673576891422, Standard Deviation: 0.005439236760139465\n",
      "PFT 1: Average lai value: 0.0015064289327710867, Standard Deviation: 0.0033408410381525755\n",
      "PFT 2: Average lai value: 0.0013280260609462857, Standard Deviation: 0.003519537625834346\n",
      "PFT 3: Average lai value: 0.00244216644205153, Standard Deviation: 0.0050758798606693745\n",
      "Processing data for time: 06\n",
      "PFT 1: Average chl value: 0.003380988957360387, Standard Deviation: 0.004389374516904354\n",
      "PFT 2: Average chl value: 0.0029149444308131933, Standard Deviation: 0.003936667460948229\n",
      "PFT 3: Average chl value: 0.0069860294461250305, Standard Deviation: 0.005423575174063444\n",
      "PFT 1: Average lai value: 0.001261204364709556, Standard Deviation: 0.0031422602478414774\n",
      "PFT 2: Average lai value: 0.0010063981171697378, Standard Deviation: 0.0026400580536574125\n",
      "PFT 3: Average lai value: 0.0018049349309876561, Standard Deviation: 0.0040515996515750885\n",
      "Processing data for time: 07\n",
      "PFT 1: Average chl value: 0.0030091397929936647, Standard Deviation: 0.004042166285216808\n",
      "PFT 2: Average chl value: 0.0025935189332813025, Standard Deviation: 0.0036294981837272644\n",
      "PFT 3: Average chl value: 0.0063145700842142105, Standard Deviation: 0.0050837271846830845\n",
      "PFT 1: Average lai value: 0.0009154543513432145, Standard Deviation: 0.0019999693613499403\n",
      "PFT 2: Average lai value: 0.0008382137748412788, Standard Deviation: 0.002042969223111868\n",
      "PFT 3: Average lai value: 0.0010830465471372008, Standard Deviation: 0.0023843145463615656\n",
      "Processing data for time: 08\n",
      "PFT 1: Average chl value: 0.0029146866872906685, Standard Deviation: 0.004039015155285597\n",
      "PFT 2: Average chl value: 0.002565424656495452, Standard Deviation: 0.0038404115475714207\n",
      "PFT 3: Average chl value: 0.0060317665338516235, Standard Deviation: 0.004997005220502615\n",
      "PFT 1: Average lai value: 0.0009949168888852, Standard Deviation: 0.0022500280756503344\n",
      "PFT 2: Average lai value: 0.0010031139245256782, Standard Deviation: 0.0030419749673455954\n",
      "PFT 3: Average lai value: 0.0009717097273096442, Standard Deviation: 0.0021009768825024366\n",
      "Processing data for time: 09\n",
      "PFT 1: Average chl value: 0.002276134677231312, Standard Deviation: 0.0035408535040915012\n",
      "PFT 2: Average chl value: 0.0019114139722660184, Standard Deviation: 0.0032134316861629486\n",
      "PFT 3: Average chl value: 0.005371856968849897, Standard Deviation: 0.004833210725337267\n",
      "PFT 1: Average lai value: 0.0007076486945152283, Standard Deviation: 0.0015882754232734442\n",
      "PFT 2: Average lai value: 0.0006653843447566032, Standard Deviation: 0.0017371834255754948\n",
      "PFT 3: Average lai value: 0.0007945008110255003, Standard Deviation: 0.0015643204096704721\n",
      "Processing data for time: 10\n",
      "PFT 1: Average chl value: 0.0023361078929156065, Standard Deviation: 0.0037085101939737797\n",
      "PFT 2: Average chl value: 0.001702791778370738, Standard Deviation: 0.00311901792883873\n",
      "PFT 3: Average chl value: 0.0051617128774523735, Standard Deviation: 0.004826975986361504\n",
      "PFT 1: Average lai value: 0.0007519208593294024, Standard Deviation: 0.001996516715735197\n",
      "PFT 2: Average lai value: 0.0007199300453066826, Standard Deviation: 0.002165879588574171\n",
      "PFT 3: Average lai value: 0.0006915520643815398, Standard Deviation: 0.0012348892632871866\n",
      "Processing data for time: 11\n",
      "PFT 1: Average chl value: 0.0018413340440019965, Standard Deviation: 0.00317760999314487\n",
      "PFT 2: Average chl value: 0.001468524569645524, Standard Deviation: 0.002834819722920656\n",
      "PFT 3: Average chl value: 0.0045112259685993195, Standard Deviation: 0.004600367974489927\n",
      "PFT 1: Average lai value: 0.0005984633462503552, Standard Deviation: 0.0010297073749825358\n",
      "PFT 2: Average lai value: 0.0005746592069044709, Standard Deviation: 0.0010463644284754992\n",
      "PFT 3: Average lai value: 0.000608137110248208, Standard Deviation: 0.000779853027779609\n",
      "Processing data for time: 12\n",
      "PFT 1: Average chl value: 0.0022041217889636755, Standard Deviation: 0.0035982111003249884\n",
      "PFT 2: Average chl value: 0.0017382991500198841, Standard Deviation: 0.003324772696942091\n",
      "PFT 3: Average chl value: 0.005135365296155214, Standard Deviation: 0.004785308614373207\n",
      "PFT 1: Average lai value: 0.0007330116932280362, Standard Deviation: 0.001340948510915041\n",
      "PFT 2: Average lai value: 0.0007098929490894079, Standard Deviation: 0.00137589150108397\n",
      "PFT 3: Average lai value: 0.0008151970105245709, Standard Deviation: 0.001607240061275661\n",
      "Data processing and saving completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Define the range of times from 00 to 12\n",
    "times = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "# Given dates\n",
    "dates = [\"2022-02-24T00:00:00.000000\", \"2022-02-28T00:00:00.000000\", \"2022-03-08T00:00:00.000000\",\n",
    "         \"2022-03-16T00:00:00.000000\", \"2022-03-22T00:00:00.000000\", \"2022-04-05T00:00:00.000000\",\n",
    "         \"2022-04-12T00:00:00.000000\", \"2022-04-20T00:00:00.000000\", \"2022-04-29T00:00:00.000000\",\n",
    "         \"2022-05-03T00:00:00.000000\", \"2022-05-11T00:00:00.000000\", \"2022-05-17T00:00:00.000000\",\n",
    "         \"2022-05-29T00:00:00.000000\"]\n",
    "\n",
    "# Extract dates without times\n",
    "dates_without_times = [date.split('T')[0] for date in dates]\n",
    "\n",
    "# Load PFT dataset\n",
    "pft_ds = xr.open_dataset('/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/California_Vegetation_WHRTYPE_Dangermond/output_latlon.nc')\n",
    "\n",
    "# Informative message: Loading datasets for all times\n",
    "print(f'Loading datasets for all times...')\n",
    "\n",
    "# Load the combined datasets for chl, lai, and lma\n",
    "chl_ds = xr.open_dataset('/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/pro_aviris_dangermond_clima_fit_reg.nc')\n",
    "lai_ds = xr.open_dataset('/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/cbc_aviris_dangermond_clima_fit_reg.nc')\n",
    "#lma_ds = xr.open_dataset('/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lma_aviris_dangermond_clima_fit_reg.nc')\n",
    "\n",
    "# Extract chl, lai, and lma values and PFT data\n",
    "chl_values = chl_ds['pro'].values\n",
    "lai_values = lai_ds['cbc'].values\n",
    "#lma_values = lma_ds['lma'].values * 10000   # Convert lma values to g.m^-2\n",
    "pft_values = pft_ds['Band1'].values  # Assuming PFT values are stored in Band1 variable\n",
    "\n",
    "# Define PFT categories (2, 3, 4)\n",
    "pft_categories = [2, 3, 4]\n",
    "\n",
    "# Create a mask for PFT categories\n",
    "pft_mask = np.isin(pft_values, pft_categories)\n",
    "\n",
    "# Initialize arrays to store new data\n",
    "new_chl_values = np.zeros_like(chl_values)\n",
    "new_std_chl_values = np.zeros_like(chl_values)\n",
    "new_lai_values = np.zeros_like(lai_values)\n",
    "new_std_lai_values = np.zeros_like(lai_values)\n",
    "#new_lma_values = np.zeros_like(lma_values)\n",
    "#new_std_lma_values = np.zeros_like(lma_values)\n",
    "\n",
    "# Loop over times\n",
    "for time_index, time in enumerate(times):\n",
    "    # Informative message: Loading datasets for the current time\n",
    "    print(f'Processing data for time: {time}')\n",
    "    \n",
    "    # Extract chl, lai, lma values for the current time\n",
    "    chl_values_time = chl_values[time_index, :, :]\n",
    "    lai_values_time = lai_values[time_index, :, :]\n",
    "    #lma_values_time = lma_values[time_index, :, :]\n",
    "    \n",
    "    # Ensure values and pft_mask have the same shape\n",
    "    masked_chl_values = np.ma.masked_where(~pft_mask, chl_values_time)\n",
    "    masked_lai_values = np.ma.masked_where(~pft_mask, lai_values_time)\n",
    "    #masked_lma_values = np.ma.masked_where(~pft_mask, lma_values_time)\n",
    "    \n",
    "    # Calculate average and std values per PFT for chl, lai, and lma\n",
    "    average_chl_per_pft = []\n",
    "    std_chl_per_pft = []\n",
    "    average_lai_per_pft = []\n",
    "    std_lai_per_pft = []\n",
    "    #average_lma_per_pft = []\n",
    "    #std_lma_per_pft = []\n",
    "\n",
    "    for pft_category in pft_categories:\n",
    "        # chl\n",
    "        pft_chl_values = masked_chl_values[pft_values == pft_category]\n",
    "        average_chl = np.nanmean(pft_chl_values)\n",
    "        std_chl = np.nanstd(pft_chl_values)\n",
    "        average_chl_per_pft.append(average_chl)\n",
    "        std_chl_per_pft.append(std_chl)\n",
    "        \n",
    "        # lai\n",
    "        pft_lai_values = masked_lai_values[pft_values == pft_category]\n",
    "        average_lai = np.nanmean(pft_lai_values)\n",
    "        std_lai = np.nanstd(pft_lai_values)\n",
    "        average_lai_per_pft.append(average_lai)\n",
    "        std_lai_per_pft.append(std_lai)\n",
    "        \n",
    "        # lma\n",
    "        #pft_lma_values = masked_lma_values[pft_values == pft_category]\n",
    "        #pft_lma_values = pft_lma_values[(~np.isnan(pft_lma_values)) & (pft_lma_values != 0)]\n",
    "        #average_lma = np.nanmean(pft_lma_values)\n",
    "        #std_lma = np.nanstd(pft_lma_values)\n",
    "        #average_lma_per_pft.append(average_lma)\n",
    "        #std_lma_per_pft.append(std_lma)\n",
    "    \n",
    "    # Print average and standard deviation values per PFT for chl, lai, and lma\n",
    "    for idx, (avg_chl, std_chl) in enumerate(zip(average_chl_per_pft, std_chl_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average chl value: {avg_chl}, Standard Deviation: {std_chl}')\n",
    "    for idx, (avg_lai, std_lai) in enumerate(zip(average_lai_per_pft, std_lai_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average lai value: {avg_lai}, Standard Deviation: {std_lai}')\n",
    "    #for idx, (avg_lma, std_lma) in enumerate(zip(average_lma_per_pft, std_lma_per_pft)):\n",
    "    #    print(f'PFT {pft_categories[idx]-1}: Average lma value: {avg_lma}, Standard Deviation: {std_lma}')\n",
    "\n",
    "    # Assign average and std values to new arrays\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)\n",
    "        new_chl_values[time_index, mask] = average_chl_per_pft[idx]\n",
    "        new_std_chl_values[time_index, mask] = std_chl_per_pft[idx]\n",
    "        new_lai_values[time_index, mask] = average_lai_per_pft[idx]\n",
    "        new_std_lai_values[time_index, mask] = std_lai_per_pft[idx]\n",
    "        #new_lma_values[time_index, mask] = average_lma_per_pft[idx]\n",
    "        #new_std_lma_values[time_index, mask] = std_lma_per_pft[idx]\n",
    "\n",
    "    # Plotting figures for each trait\n",
    "\n",
    "    # Creating plots for all PFTs for chl\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size\n",
    "    colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)\n",
    "        \n",
    "        # Extract chl values for the current PFT category\n",
    "        chl_for_pft = masked_chl_values[mask].compressed()\n",
    "        avg_chl = average_chl_per_pft[idx]\n",
    "        std_chl = std_chl_per_pft[idx]\n",
    "\n",
    "        # Create a histogram for chl values with transparency\n",
    "        plt.hist(chl_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "\n",
    "        # Add a vertical line for the average\n",
    "        plt.axvline(avg_chl, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Prepare text for the legend\n",
    "        avg_std_text = f'{avg_chl:.2e} ± {std_chl:.2e}'\n",
    "        legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "    plt.title(f'Combined PRO Distribution ({dates_without_times[time_index]})', fontsize=18)\n",
    "    plt.xlabel(r'PRO Value (g.cm$^{-2}$)', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.ylim(0, 200)  # Set y-axis limits\n",
    "    plt.xlim(0, 0.015)  # Set y-axis limits\n",
    "    plt.legend(legend_labels, fontsize=14)  # Increase legend fontsize\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick label fontsize\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick label fontsize\n",
    "\n",
    "    # Save the combined plot as a PNG file\n",
    "    plt.savefig(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/combined_pro_histogram_time_{time}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Creating plots for all PFTs for lai\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size\n",
    "    colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)\n",
    "        \n",
    "        # Extract lai values for the current PFT category\n",
    "        lai_for_pft = masked_lai_values[mask].compressed()\n",
    "        avg_lai = average_lai_per_pft[idx]\n",
    "        std_lai = std_lai_per_pft[idx]\n",
    "\n",
    "        # Create a histogram for lai values with transparency\n",
    "        plt.hist(lai_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "\n",
    "        # Add a vertical line for the average\n",
    "        plt.axvline(avg_lai, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Prepare text for the legend\n",
    "        avg_std_text = f'{avg_lai:.2e} ± {std_lai:.2e}'\n",
    "        legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "    plt.title(f'Combined CBC Distribution ({dates_without_times[time_index]})', fontsize=18)\n",
    "    plt.xlabel(r'CBC Value (g.cm$^{-2}$)', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.ylim(0, 200)  # Set y-axis limits\n",
    "    plt.xlim(0, 0.035)  # Set y-axis limits\n",
    "    plt.legend(legend_labels, fontsize=14)  # Increase legend fontsize\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick label fontsize\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick label fontsize\n",
    "\n",
    "    # Save the combined plot as a PNG file\n",
    "    plt.savefig(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/combined_cbc_histogram_time_{time}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Replace zeros by NaN in new maps\n",
    "new_chl_values = np.where(new_chl_values != 0, new_chl_values, np.nan)\n",
    "new_std_chl_values = np.where(new_std_chl_values != 0, new_std_chl_values, np.nan)\n",
    "new_lai_values = np.where(new_lai_values != 0, new_lai_values, np.nan)\n",
    "new_std_lai_values = np.where(new_std_lai_values != 0, new_std_lai_values, np.nan)\n",
    "#new_lma_values = np.where(new_lma_values != 0, new_lma_values, np.nan)\n",
    "#new_std_lma_values = np.where(new_std_lma_values != 0, new_std_lma_values, np.nan)\n",
    "\n",
    "# Save the new datasets to NetCDF files\n",
    "new_chl_ds = xr.Dataset({\n",
    "    'pro': (('time', 'lat', 'lon'), new_chl_values),\n",
    "    'std_pro': (('time', 'lat', 'lon'), new_std_chl_values)},\n",
    "    coords={'time': chl_ds['time'], 'lat': chl_ds['lat'], 'lon': chl_ds['lon']})\n",
    "new_chl_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_pro_aviris_dangermond_clima_fit.nc')\n",
    "\n",
    "new_lai_ds = xr.Dataset({\n",
    "    'cbc': (('time', 'lat', 'lon'), new_lai_values),\n",
    "    'std_cbc': (('time', 'lat', 'lon'), new_std_lai_values)},\n",
    "    coords={'time': lai_ds['time'], 'lat': lai_ds['lat'], 'lon': lai_ds['lon']})\n",
    "new_lai_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_cbc_aviris_dangermond_clima_fit.nc')\n",
    "\n",
    "#new_lma_ds = xr.Dataset({\n",
    "#    'lma': (('time', 'lat', 'lon'), new_lma_values),\n",
    "#    'std_lma': (('time', 'lat', 'lon'), new_std_lma_values)},\n",
    "#    coords={'time': lma_ds['time'], 'lat': lma_ds['lat'], 'lon': lma_ds['lon']})\n",
    "#new_lma_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lma_aviris_dangermond_clima_fit.nc')\n",
    "\n",
    "# Informative message: Data processing and saving completed\n",
    "print(f'Data processing and saving completed.\\n')\n",
    "\n",
    "# Close the opened datasets\n",
    "chl_ds.close()\n",
    "lai_ds.close()\n",
    "#lma_ds.close()\n",
    "pft_ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87949d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for time: 00\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 46.729957580566406, Standard Deviation: 24.14640235900879\n",
      "PFT 2: Average chl value: 41.99604415893555, Standard Deviation: 23.10335922241211\n",
      "PFT 3: Average chl value: 61.09103012084961, Standard Deviation: 21.684953689575195\n",
      "PFT 1: Average lai value: 3.1625101566314697, Standard Deviation: 4.1916093826293945\n",
      "PFT 2: Average lai value: 2.9527974128723145, Standard Deviation: 4.051224231719971\n",
      "PFT 3: Average lai value: 5.522914886474609, Standard Deviation: 5.532774925231934\n",
      "PFT 1: Average lma value: 0.007947982288897038, Standard Deviation: 0.010108904913067818\n",
      "PFT 2: Average lma value: 0.00682315556332469, Standard Deviation: 0.009396327659487724\n",
      "PFT 3: Average lma value: 0.015052175149321556, Standard Deviation: 0.013613208197057247\n",
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 00\n",
      "\n",
      "Processing data for time: 01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 43.979766845703125, Standard Deviation: 24.082256317138672\n",
      "PFT 2: Average chl value: 39.70149612426758, Standard Deviation: 22.693452835083008\n",
      "PFT 3: Average chl value: 59.3845100402832, Standard Deviation: 22.051124572753906\n",
      "PFT 1: Average lai value: 2.801231861114502, Standard Deviation: 3.8114562034606934\n",
      "PFT 2: Average lai value: 2.6050188541412354, Standard Deviation: 3.6731910705566406\n",
      "PFT 3: Average lai value: 4.929548740386963, Standard Deviation: 4.960460186004639\n",
      "PFT 1: Average lma value: 0.0067498404532670975, Standard Deviation: 0.008963307365775108\n",
      "PFT 2: Average lma value: 0.005778426304459572, Standard Deviation: 0.00836808793246746\n",
      "PFT 3: Average lma value: 0.013094979338347912, Standard Deviation: 0.01219993643462658\n",
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 01\n",
      "\n",
      "Processing data for time: 02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 44.33891677856445, Standard Deviation: 23.780895233154297\n",
      "PFT 2: Average chl value: 38.91999816894531, Standard Deviation: 22.307130813598633\n",
      "PFT 3: Average chl value: 58.3569221496582, Standard Deviation: 21.672563552856445\n",
      "PFT 1: Average lai value: 2.861719846725464, Standard Deviation: 3.898144483566284\n",
      "PFT 2: Average lai value: 2.580091714859009, Standard Deviation: 3.7050416469573975\n",
      "PFT 3: Average lai value: 5.027500629425049, Standard Deviation: 5.013463497161865\n",
      "PFT 1: Average lma value: 0.007191690616309643, Standard Deviation: 0.00894811749458313\n",
      "PFT 2: Average lma value: 0.006057251710444689, Standard Deviation: 0.008076006546616554\n",
      "PFT 3: Average lma value: 0.013003963977098465, Standard Deviation: 0.011609423905611038\n",
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 02\n",
      "\n",
      "Processing data for time: 03\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 35.97517395019531, Standard Deviation: 22.465438842773438\n",
      "PFT 2: Average chl value: 32.30778884887695, Standard Deviation: 20.475276947021484\n",
      "PFT 3: Average chl value: 52.737125396728516, Standard Deviation: 22.575523376464844\n",
      "PFT 1: Average lai value: 2.337899684906006, Standard Deviation: 3.1660783290863037\n",
      "PFT 2: Average lai value: 2.2149858474731445, Standard Deviation: 3.1408309936523438\n",
      "PFT 3: Average lai value: 4.379950523376465, Standard Deviation: 4.262785911560059\n",
      "PFT 1: Average lma value: 0.005545346532016993, Standard Deviation: 0.006928735412657261\n",
      "PFT 2: Average lma value: 0.00491532776504755, Standard Deviation: 0.006408201064914465\n",
      "PFT 3: Average lma value: 0.010968517512083054, Standard Deviation: 0.009610921144485474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 03\n",
      "\n",
      "Processing data for time: 04\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 44.33628463745117, Standard Deviation: 23.3028564453125\n",
      "PFT 2: Average chl value: 39.12870788574219, Standard Deviation: 22.04659080505371\n",
      "PFT 3: Average chl value: 57.25511932373047, Standard Deviation: 21.361536026000977\n",
      "PFT 1: Average lai value: 2.5401611328125, Standard Deviation: 3.725193500518799\n",
      "PFT 2: Average lai value: 2.345837116241455, Standard Deviation: 3.6323347091674805\n",
      "PFT 3: Average lai value: 4.758341312408447, Standard Deviation: 4.845849514007568\n",
      "PFT 1: Average lma value: 0.006876408588141203, Standard Deviation: 0.00825174618512392\n",
      "PFT 2: Average lma value: 0.005905728321522474, Standard Deviation: 0.007302793674170971\n",
      "PFT 3: Average lma value: 0.011793714016675949, Standard Deviation: 0.010475073009729385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 04\n",
      "\n",
      "Processing data for time: 05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 33.892906188964844, Standard Deviation: 20.589265823364258\n",
      "PFT 2: Average chl value: 29.334959030151367, Standard Deviation: 18.320785522460938\n",
      "PFT 3: Average chl value: 51.1032600402832, Standard Deviation: 21.552085876464844\n",
      "PFT 1: Average lai value: 2.0008904933929443, Standard Deviation: 2.5605907440185547\n",
      "PFT 2: Average lai value: 1.9591240882873535, Standard Deviation: 2.7923312187194824\n",
      "PFT 3: Average lai value: 3.8213491439819336, Standard Deviation: 3.4363958835601807\n",
      "PFT 1: Average lma value: 0.005179934669286013, Standard Deviation: 0.0057813432067632675\n",
      "PFT 2: Average lma value: 0.0047063580714166164, Standard Deviation: 0.005884181242436171\n",
      "PFT 3: Average lma value: 0.009872839786112309, Standard Deviation: 0.00783076137304306\n",
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 05\n",
      "\n",
      "Processing data for time: 06\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 29.26422119140625, Standard Deviation: 20.33661651611328\n",
      "PFT 2: Average chl value: 24.155784606933594, Standard Deviation: 17.312219619750977\n",
      "PFT 3: Average chl value: 45.61111831665039, Standard Deviation: 22.502614974975586\n",
      "PFT 1: Average lai value: 1.7186317443847656, Standard Deviation: 2.4869611263275146\n",
      "PFT 2: Average lai value: 1.5307230949401855, Standard Deviation: 2.3183906078338623\n",
      "PFT 3: Average lai value: 3.257086753845215, Standard Deviation: 3.055248260498047\n",
      "PFT 1: Average lma value: 0.004642193671315908, Standard Deviation: 0.005771165248006582\n",
      "PFT 2: Average lma value: 0.003921342547982931, Standard Deviation: 0.005028424318879843\n",
      "PFT 3: Average lma value: 0.008790964260697365, Standard Deviation: 0.00712042348459363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 06\n",
      "\n",
      "Processing data for time: 07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 24.52532196044922, Standard Deviation: 17.936996459960938\n",
      "PFT 2: Average chl value: 20.45149803161621, Standard Deviation: 15.489215850830078\n",
      "PFT 3: Average chl value: 38.418060302734375, Standard Deviation: 20.700109481811523\n",
      "PFT 1: Average lai value: 1.2239078283309937, Standard Deviation: 1.7350810766220093\n",
      "PFT 2: Average lai value: 1.116944432258606, Standard Deviation: 1.801390528678894\n",
      "PFT 3: Average lai value: 2.3476502895355225, Standard Deviation: 2.172451972961426\n",
      "PFT 1: Average lma value: 0.003924593795090914, Standard Deviation: 0.004614424426108599\n",
      "PFT 2: Average lma value: 0.003431732766330242, Standard Deviation: 0.004296206869184971\n",
      "PFT 3: Average lma value: 0.007397616747766733, Standard Deviation: 0.0057173920795321465\n",
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 07\n",
      "\n",
      "Processing data for time: 08\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 24.886810302734375, Standard Deviation: 17.368656158447266\n",
      "PFT 2: Average chl value: 20.953990936279297, Standard Deviation: 15.787999153137207\n",
      "PFT 3: Average chl value: 37.59053421020508, Standard Deviation: 19.639442443847656\n",
      "PFT 1: Average lai value: 1.2465170621871948, Standard Deviation: 1.8182626962661743\n",
      "PFT 2: Average lai value: 1.2171220779418945, Standard Deviation: 2.294240713119507\n",
      "PFT 3: Average lai value: 2.3000566959381104, Standard Deviation: 2.1096510887145996\n",
      "PFT 1: Average lma value: 0.00390960369259119, Standard Deviation: 0.004736128728836775\n",
      "PFT 2: Average lma value: 0.003568538697436452, Standard Deviation: 0.005376187153160572\n",
      "PFT 3: Average lma value: 0.007003475911915302, Standard Deviation: 0.00549296336248517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 08\n",
      "\n",
      "Processing data for time: 09\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 18.28829002380371, Standard Deviation: 15.582550048828125\n",
      "PFT 2: Average chl value: 14.814322471618652, Standard Deviation: 12.176765441894531\n",
      "PFT 3: Average chl value: 31.746946334838867, Standard Deviation: 19.475624084472656\n",
      "PFT 1: Average lai value: 0.8554477095603943, Standard Deviation: 1.3896745443344116\n",
      "PFT 2: Average lai value: 0.7296227216720581, Standard Deviation: 1.4056288003921509\n",
      "PFT 3: Average lai value: 1.8511911630630493, Standard Deviation: 1.7509791851043701\n",
      "PFT 1: Average lma value: 0.00298378337174654, Standard Deviation: 0.004029806703329086\n",
      "PFT 2: Average lma value: 0.0025767982006073, Standard Deviation: 0.003838189411908388\n",
      "PFT 3: Average lma value: 0.006166358012706041, Standard Deviation: 0.005133980419486761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 09\n",
      "\n",
      "Processing data for time: 10\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 17.539751052856445, Standard Deviation: 15.556224822998047\n",
      "PFT 2: Average chl value: 12.771330833435059, Standard Deviation: 12.414155006408691\n",
      "PFT 3: Average chl value: 29.05889320373535, Standard Deviation: 18.78983497619629\n",
      "PFT 1: Average lai value: 0.86321622133255, Standard Deviation: 1.6881896257400513\n",
      "PFT 2: Average lai value: 0.6527736186981201, Standard Deviation: 1.5737149715423584\n",
      "PFT 3: Average lai value: 1.6189684867858887, Standard Deviation: 1.591029405593872\n",
      "PFT 1: Average lma value: 0.0030880288686603308, Standard Deviation: 0.0044477591291069984\n",
      "PFT 2: Average lma value: 0.0024227218236774206, Standard Deviation: 0.004062011372298002\n",
      "PFT 3: Average lma value: 0.005853264592587948, Standard Deviation: 0.005022504832595587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 10\n",
      "\n",
      "Processing data for time: 11\n",
      "Extracting data from the loaded datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFT 1: Average chl value: 14.704618453979492, Standard Deviation: 13.157190322875977\n",
      "PFT 2: Average chl value: 10.984109878540039, Standard Deviation: 10.957596778869629\n",
      "PFT 3: Average chl value: 25.19135093688965, Standard Deviation: 17.3702392578125\n",
      "PFT 1: Average lai value: 0.6348601579666138, Standard Deviation: 1.0916554927825928\n",
      "PFT 2: Average lai value: 0.5095308423042297, Standard Deviation: 1.0565277338027954\n",
      "PFT 3: Average lai value: 1.433714509010315, Standard Deviation: 1.4804470539093018\n",
      "PFT 1: Average lma value: 0.0024397976230829954, Standard Deviation: 0.0034071665722876787\n",
      "PFT 2: Average lma value: 0.0020431841257959604, Standard Deviation: 0.0031012122053653\n",
      "PFT 3: Average lma value: 0.005119363311678171, Standard Deviation: 0.004693000111728907\n",
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 11\n",
      "\n",
      "Processing data for time: 12\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 19.905723571777344, Standard Deviation: 15.388687133789062\n",
      "PFT 2: Average chl value: 15.963467597961426, Standard Deviation: 14.426827430725098\n",
      "PFT 3: Average chl value: 31.564367294311523, Standard Deviation: 18.594419479370117\n",
      "PFT 1: Average lai value: 0.7717059850692749, Standard Deviation: 1.2931026220321655\n",
      "PFT 2: Average lai value: 0.6322526931762695, Standard Deviation: 1.3178621530532837\n",
      "PFT 3: Average lai value: 1.7237370014190674, Standard Deviation: 1.7811442613601685\n",
      "PFT 1: Average lma value: 0.0029371334239840508, Standard Deviation: 0.0039012765046209097\n",
      "PFT 2: Average lma value: 0.0024481918662786484, Standard Deviation: 0.003693418577313423\n",
      "PFT 3: Average lma value: 0.005950562190264463, Standard Deviation: 0.005097059067338705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1019687553.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Define the range of times from 00 to 12\n",
    "times = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "# Given dates\n",
    "dates = [\"2022-02-24T00:00:00.000000\", \"2022-02-28T00:00:00.000000\", \"2022-03-08T00:00:00.000000\",\n",
    "         \"2022-03-16T00:00:00.000000\", \"2022-03-22T00:00:00.000000\", \"2022-04-05T00:00:00.000000\",\n",
    "         \"2022-04-12T00:00:00.000000\", \"2022-04-20T00:00:00.000000\", \"2022-04-29T00:00:00.000000\",\n",
    "         \"2022-05-03T00:00:00.000000\", \"2022-05-11T00:00:00.000000\", \"2022-05-17T00:00:00.000000\",\n",
    "         \"2022-05-29T00:00:00.000000\"]\n",
    "\n",
    "# Extract dates without times\n",
    "dates_without_times = [date.split('T')[0] for date in dates]\n",
    "\n",
    "# Loop over times\n",
    "for time in times:\n",
    "\n",
    "    # Informative message: Loading datasets for the current time\n",
    "    print(f'Processing data for time: {time}')\n",
    "    \n",
    "    # Load chl and PFT datasets for the current time\n",
    "    chl_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/chl_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    lai_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lwc_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    lma_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lma_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    pft_ds = xr.open_dataset(f'../California_Vegetation_WHRTYPE_Dangermond/output_latlon.nc')  # Update the PFT dataset filename\n",
    "    \n",
    "    # Informative message: Extracting data from the loaded datasets\n",
    "    print('Extracting data from the loaded datasets...')\n",
    "    \n",
    "    # Extract chl values and PFT data\n",
    "    chl_values = chl_ds['chl'].values\n",
    "    lai_values = lai_ds['lwc'].values\n",
    "    lma_values = lma_ds['lma'].values\n",
    "    pft_values = pft_ds['Band1'].values  # Assuming PFT values are stored in Band1 variable\n",
    "    \n",
    "    # Define PFT categories (2, 3, 4)\n",
    "    pft_categories = [2, 3, 4]\n",
    "    \n",
    "    # Create a mask for PFT categories\n",
    "    pft_mask = np.isin(pft_values, pft_categories)\n",
    "    \n",
    "    # Ensure chl_values and pft_mask have the same shape\n",
    "    masked_chl_values = np.ma.masked_where(~pft_mask[:, :], chl_values[0, :, :])\n",
    "    masked_lai_values = np.ma.masked_where(~pft_mask[:, :], lai_values[0, :, :])\n",
    "    masked_lma_values = np.ma.masked_where(~pft_mask[:, :], lma_values[0, :, :])\n",
    "    \n",
    "    # Calculate average chl value per PFT\n",
    "    average_chl_per_pft = []\n",
    "    std_chl_per_pft = []\n",
    "    average_lai_per_pft = []\n",
    "    std_lai_per_pft = []\n",
    "    average_lma_per_pft = []\n",
    "    std_lma_per_pft = []\n",
    "    for pft_category in pft_categories:\n",
    "        # chl\n",
    "        pft_chl_values = masked_chl_values[pft_values[:, :] == pft_category]\n",
    "        average_chl = np.nanmean(pft_chl_values)\n",
    "        std_chl = np.nanstd(pft_chl_values)\n",
    "        average_chl_per_pft.append(average_chl)\n",
    "        std_chl_per_pft.append(std_chl)\n",
    "        \n",
    "        # lai\n",
    "        pft_lai_values = masked_lai_values[pft_values[:, :] == pft_category]\n",
    "        average_lai = np.nanmean(pft_lai_values)\n",
    "        std_lai = np.nanstd(pft_lai_values)\n",
    "        average_lai_per_pft.append(average_lai)\n",
    "        std_lai_per_pft.append(std_lai)\n",
    "        \n",
    "        # lma\n",
    "        pft_lma_values = masked_lma_values[pft_values[:, :] == pft_category]\n",
    "        pft_lma_values = pft_lma_values[(~np.isnan(pft_lma_values)) & (pft_lma_values != 0)]\n",
    "        average_lma = np.nanmean(pft_lma_values)\n",
    "        std_lma = np.nanstd(pft_lma_values)\n",
    "        average_lma_per_pft.append(average_lma)\n",
    "        std_lma_per_pft.append(std_lma)\n",
    "    \n",
    "    # Print average and standard deviation chl values per PFT\n",
    "    for idx, (avg_chl, std_chl) in enumerate(zip(average_chl_per_pft, std_chl_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average chl value: {avg_chl}, Standard Deviation: {std_chl}')\n",
    "\n",
    "    # Print average and standard deviation lai values per PFT\n",
    "    for idx, (avg_lai, std_lai) in enumerate(zip(average_lai_per_pft, std_lai_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average lai value: {avg_lai}, Standard Deviation: {std_lai}')\n",
    "\n",
    "    # Print average and standard deviation lma values per PFT\n",
    "    for idx, (avg_lma, std_lma) in enumerate(zip(average_lma_per_pft, std_lma_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx]-1}: Average lma value: {avg_lma}, Standard Deviation: {std_lma}')\n",
    "\n",
    "    # Optionally, save the new chl map with masked values\n",
    "    # chl_ds['chl'][:] = masked_chl_values\n",
    "    # chl_ds.to_netcdf('masked_chl_aviris_dangermond.nc')\n",
    "\n",
    "    # Create a new chl map with average values per PFT\n",
    "    new_chl_values = np.zeros_like(chl_values[0,:,:])\n",
    "    new_std_chl_values = np.zeros_like(chl_values[0,:,:])\n",
    "    new_lai_values = np.zeros_like(lai_values[0,:,:])\n",
    "    new_std_lai_values = np.zeros_like(lai_values[0,:,:])\n",
    "    new_lma_values = np.zeros_like(lma_values[0,:,:])\n",
    "    new_std_lma_values = np.zeros_like(lma_values[0,:,:])\n",
    "\n",
    "\n",
    "    # Creating plots for all PFTs for chl\n",
    "    #plt.figure()\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size\n",
    "    colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)[:, :]\n",
    "        new_chl_values[mask] = average_chl_per_pft[idx]\n",
    "        new_std_chl_values[mask] = std_chl_per_pft[idx]\n",
    "        #new_lai_values[mask] = average_lai_per_pft[idx]\n",
    "        #new_std_lai_values[mask] = std_lai_per_pft[idx]\n",
    "        #new_lma_values[mask] = average_lma_per_pft[idx]\n",
    "        #new_std_lma_values[mask] = std_lma_per_pft[idx]\n",
    "\n",
    "        # Extract chl values for the current PFT category\n",
    "        chl_for_pft = masked_chl_values[pft_values == pft_category].compressed()\n",
    "        avg_chl = average_chl_per_pft[idx]\n",
    "        std_chl = std_chl_per_pft[idx]\n",
    "\n",
    "        # Create a histogram for chl values with transparency\n",
    "        plt.hist(chl_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "\n",
    "        # Add a vertical line for the average\n",
    "        plt.axvline(avg_chl, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Prepare text for the legend\n",
    "        avg_std_text = f'{avg_chl:.2f} ± {std_chl:.2f}'\n",
    "        legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "    plt.title(f'Combined CHL Distribution ({dates_without_times[int(time)]})', fontsize=18)\n",
    "    plt.xlabel(r'CHL Value ($\\mu$g.cm$^{-2}$)', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.ylim(0, 0.5)  # Set y-axis limits\n",
    "    plt.xlim(0, 20)  # Set y-axis limits\n",
    "    plt.legend(legend_labels, fontsize=14)  # Increase legend fontsize\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick label fontsize\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick label fontsize\n",
    "\n",
    "    # Save the combined plot as a PNG file\n",
    "    #plt.savefig(f'combined_chl_histogram_time_{time}.png',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Creating plots for all PFTs for lai\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size\n",
    "    colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)[:, :]\n",
    "        #new_chl_values[mask] = average_chl_per_pft[idx]\n",
    "        #new_std_chl_values[mask] = std_chl_per_pft[idx]\n",
    "        new_lai_values[mask] = average_lai_per_pft[idx]\n",
    "        new_std_lai_values[mask] = std_lai_per_pft[idx]\n",
    "        #new_lma_values[mask] = average_lma_per_pft[idx]\n",
    "        #new_std_lma_values[mask] = std_lma_per_pft[idx]\n",
    "\n",
    "        # Extract chl values for the current PFT category\n",
    "        lai_for_pft = masked_lai_values[pft_values == pft_category].compressed()\n",
    "        avg_lai = average_lai_per_pft[idx]\n",
    "        std_lai = std_lai_per_pft[idx]\n",
    "\n",
    "        # Create a histogram for chl values with transparency\n",
    "        plt.hist(lai_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "\n",
    "        # Add a vertical line for the average\n",
    "        plt.axvline(avg_lai, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Prepare text for the legend\n",
    "        avg_std_text = f'{avg_lai:.2f} ± {std_lai:.2f}'\n",
    "        legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "    plt.title(f'Combined LAI Distribution ({dates_without_times[int(time)]})', fontsize=18)\n",
    "    plt.xlabel(r'LAI Value (m$^{2}$.m$^{-2}$)', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.ylim(0, 1.0)  # Set y-axis limits\n",
    "    plt.xlim(0, 7.5)  # Set y-axis limits\n",
    "    plt.legend(legend_labels, fontsize=14)  # Increase legend fontsize\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick label fontsize\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick label fontsize\n",
    "\n",
    "    # Save the combined plot as a PNG file\n",
    "    #plt.savefig(f'combined_lai_histogram_time_{time}.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Creating plots for all PFTs for lma\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size\n",
    "    colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)[:, :]\n",
    "        #new_chl_values[mask] = average_chl_per_pft[idx]\n",
    "        #new_std_chl_values[mask] = std_chl_per_pft[idx]\n",
    "        #new_lai_values[mask] = average_lai_per_pft[idx]\n",
    "        #new_std_lai_values[mask] = std_lai_per_pft[idx]\n",
    "        new_lma_values[mask] = average_lma_per_pft[idx]\n",
    "        new_std_lma_values[mask] = std_lma_per_pft[idx]\n",
    "\n",
    "        # Extract chl values for the current PFT category\n",
    "        lma_for_pft = masked_lma_values[pft_values == pft_category].compressed()\n",
    "        avg_lma = average_lma_per_pft[idx]\n",
    "        std_lma = std_lma_per_pft[idx]\n",
    "\n",
    "        # Create a histogram for chl values with transparency\n",
    "        plt.hist(lma_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "\n",
    "        # Add a vertical line for the average\n",
    "        plt.axvline(avg_lma, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Prepare text for the legend\n",
    "        avg_std_text = f'{avg_lma:.2e} ± {std_lma:.2e}'\n",
    "        legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "    print(np.min(lma_for_pft),np.max(lma_for_pft))\n",
    "    plt.title(f'Combined LMA Distribution ({dates_without_times[int(time)]})', fontsize=18)\n",
    "    plt.xlabel(r'LMA Value (g.cm$^{-2}$)', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.ylim(0, 800)  # Set y-axis limits\n",
    "    plt.xlim(0, 0.03)  # Set y-axis limits\n",
    "    plt.legend(legend_labels, fontsize=14)  # Increase legend fontsize\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick label fontsize\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick label fontsize\n",
    "\n",
    "    # Save the combined plot as a PNG file\n",
    "    #plt.savefig(f'combined_lma_histogram_time_{time}.png')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "\n",
    "    # Create new xarray DataArrays for chl and std\n",
    "    new_chl_da = xr.DataArray(new_chl_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': chl_ds['time'], 'lat': chl_ds['lat'], 'lon': chl_ds['lon']})\n",
    "    new_std_chl_da = xr.DataArray(new_std_chl_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': chl_ds['time'], 'lat': chl_ds['lat'], 'lon': chl_ds['lon']})\n",
    "\n",
    "\n",
    "    # Replace zeros by NaN in new maps\n",
    "    new_chl_da = new_chl_da.where(new_chl_da != 0, np.nan)\n",
    "    new_std_chl_da = new_std_chl_da.where(new_std_chl_da != 0, np.nan)\n",
    "\n",
    "    # Create a new xarray Dataset with chl and std DataArrays\n",
    "    new_chl_data = {'chl': new_chl_da, 'std': new_std_chl_da}\n",
    "    new_chl_ds = xr.Dataset(new_chl_data)\n",
    "    \n",
    "\n",
    "    # Save the new chl map with masked values and standard deviation to a NetCDF file\n",
    "    new_chl_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_chl_aviris_dangermond_time_{time}.nc')\n",
    "\n",
    "    print(lai_values.shape)\n",
    "    print(new_lai_values.shape)\n",
    "    # Create new xarray DataArrays for lai and std\n",
    "    #new_lai_da = xr.DataArray(new_lai_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': lai_ds['time'], 'lat': lai_ds['lat'], 'lon': lai_ds['lon']})\n",
    "    lai_values = np.clip(lai_values, 1e-1, 20.)  # Clip values between 0.1 and max_lai\n",
    "    new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n",
    "    \n",
    "    new_lai_da = xr.DataArray(new_lai_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': lai_ds['time'], 'lat': lai_ds['lat'], 'lon': lai_ds['lon']})\n",
    "    new_std_lai_da = xr.DataArray(new_std_lai_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': lai_ds['time'], 'lat': lai_ds['lat'], 'lon': lai_ds['lon']})\n",
    "    \n",
    "    # Replace zeros by NaN in new maps\n",
    "    new_lai_da = new_lai_da.where(new_lai_da != 0, np.nan)\n",
    "    new_lai_da = new_lai_da.where(~np.isnan(new_lai_da), np.nan)\n",
    "\n",
    "    new_std_lai_da = new_std_lai_da.where(new_std_lai_da != 0, np.nan)\n",
    "\n",
    "    # Create a new xarray Dataset with lai and std DataArrays\n",
    "    new_lai_data = {'lwc': new_lai_da, 'std': new_std_lai_da}\n",
    "    new_lai_ds = xr.Dataset(new_lai_data)\n",
    "    \n",
    "    # Save the new lai map with masked values and standard deviation to a NetCDF file\n",
    "    new_lai_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lwc_aviris_dangermond_time_{time}.nc')\n",
    "\n",
    "    # Create new xarray DataArrays for lma and std\n",
    "    new_lma_da = xr.DataArray(new_lma_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': lma_ds['time'], 'lat': lma_ds['lat'], 'lon': lma_ds['lon']})\n",
    "    new_std_lma_da = xr.DataArray(new_std_lma_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': lma_ds['time'], 'lat': lma_ds['lat'], 'lon': lma_ds['lon']})\n",
    "    \n",
    "    new_lma_da = new_lma_da.where(new_lma_da != 0, np.nan)\n",
    "    new_std_lma_da = new_std_lma_da.where(new_std_lma_da != 0, np.nan)\n",
    "\n",
    "    # Create a new xarray Dataset with lma and std DataArrays\n",
    "    new_lma_data = {'lma': new_lma_da, 'std': new_std_lma_da}\n",
    "    new_lma_ds = xr.Dataset(new_lma_data)\n",
    "    \n",
    "\n",
    "\n",
    "    # Save the new lma map with masked values and standard deviation to a NetCDF file\n",
    "    new_lma_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lma_aviris_dangermond_time_{time}.nc')\n",
    "    \n",
    "    \n",
    "    # Informative message: Data processing and saving completed for the current time\n",
    "    print(f'Data processing and saving completed for time: {time}\\n')\n",
    "\n",
    "    # Close the opened datasets\n",
    "    chl_ds.close()\n",
    "    lai_ds.close()\n",
    "    lma_ds.close()\n",
    "    pft_ds.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a7feb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for time: 00\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0037749402690678835, Standard Deviation: 0.004777900874614716\n",
      "PFT 2: Average chl value: 0.003240694059059024, Standard Deviation: 0.00432511605322361\n",
      "PFT 3: Average chl value: 0.007597974967211485, Standard Deviation: 0.0058870441280305386\n",
      "PFT 1: Average lai value: 0.004173042252659798, Standard Deviation: 0.007828260771930218\n",
      "PFT 2: Average lai value: 0.0035824610386043787, Standard Deviation: 0.007319921627640724\n",
      "PFT 3: Average lai value: 0.007454197853803635, Standard Deviation: 0.010692716576159\n",
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 00\n",
      "\n",
      "Processing data for time: 01\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.003352547064423561, Standard Deviation: 0.00452774902805686\n",
      "PFT 2: Average chl value: 0.002853008219972253, Standard Deviation: 0.004072333686053753\n",
      "PFT 3: Average chl value: 0.00705363554880023, Standard Deviation: 0.0057800025679171085\n",
      "PFT 1: Average lai value: 0.003397292923182249, Standard Deviation: 0.006799566093832254\n",
      "PFT 2: Average lai value: 0.002925417385995388, Standard Deviation: 0.006350627169013023\n",
      "PFT 3: Average lai value: 0.006041343789547682, Standard Deviation: 0.009441041387617588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 01\n",
      "\n",
      "Processing data for time: 02\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0038975533097982407, Standard Deviation: 0.0047516063787043095\n",
      "PFT 2: Average chl value: 0.0033831472974270582, Standard Deviation: 0.004306357353925705\n",
      "PFT 3: Average chl value: 0.0076296767219901085, Standard Deviation: 0.005794881843030453\n",
      "PFT 1: Average lai value: 0.0032941377721726894, Standard Deviation: 0.006763093173503876\n",
      "PFT 2: Average lai value: 0.002674104878678918, Standard Deviation: 0.005923988297581673\n",
      "PFT 3: Average lai value: 0.005374286323785782, Standard Deviation: 0.008912402205169201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 02\n",
      "\n",
      "Processing data for time: 03\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0036316080950200558, Standard Deviation: 0.004560751374810934\n",
      "PFT 2: Average chl value: 0.0031995773315429688, Standard Deviation: 0.004158773459494114\n",
      "PFT 3: Average chl value: 0.007487156894057989, Standard Deviation: 0.005719374865293503\n",
      "PFT 1: Average lai value: 0.0019137379713356495, Standard Deviation: 0.004488872364163399\n",
      "PFT 2: Average lai value: 0.0017157497350126505, Standard Deviation: 0.004157334566116333\n",
      "PFT 3: Average lai value: 0.00348135968670249, Standard Deviation: 0.0067891874350607395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 03\n",
      "\n",
      "Processing data for time: 04\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.003882898483425379, Standard Deviation: 0.004586655180901289\n",
      "PFT 2: Average chl value: 0.003580323653295636, Standard Deviation: 0.0043063415214419365\n",
      "PFT 3: Average chl value: 0.007419775240123272, Standard Deviation: 0.005636432208120823\n",
      "PFT 1: Average lai value: 0.0029935103375464678, Standard Deviation: 0.006329220719635487\n",
      "PFT 2: Average lai value: 0.002325404202565551, Standard Deviation: 0.005254601128399372\n",
      "PFT 3: Average lai value: 0.004373938776552677, Standard Deviation: 0.007964866235852242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 04\n",
      "\n",
      "Processing data for time: 05\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.003673505736514926, Standard Deviation: 0.0043962085619568825\n",
      "PFT 2: Average chl value: 0.0033783316612243652, Standard Deviation: 0.004091169219464064\n",
      "PFT 3: Average chl value: 0.007430673576891422, Standard Deviation: 0.005439236760139465\n",
      "PFT 1: Average lai value: 0.0015064289327710867, Standard Deviation: 0.0033408410381525755\n",
      "PFT 2: Average lai value: 0.0013280260609462857, Standard Deviation: 0.003519537625834346\n",
      "PFT 3: Average lai value: 0.00244216644205153, Standard Deviation: 0.0050758798606693745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 05\n",
      "\n",
      "Processing data for time: 06\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.003380988957360387, Standard Deviation: 0.004389374516904354\n",
      "PFT 2: Average chl value: 0.0029149444308131933, Standard Deviation: 0.003936667460948229\n",
      "PFT 3: Average chl value: 0.0069860294461250305, Standard Deviation: 0.005423575174063444\n",
      "PFT 1: Average lai value: 0.001261204364709556, Standard Deviation: 0.0031422602478414774\n",
      "PFT 2: Average lai value: 0.0010063981171697378, Standard Deviation: 0.0026400580536574125\n",
      "PFT 3: Average lai value: 0.0018049349309876561, Standard Deviation: 0.0040515996515750885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 06\n",
      "\n",
      "Processing data for time: 07\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0030091397929936647, Standard Deviation: 0.004042166285216808\n",
      "PFT 2: Average chl value: 0.0025935189332813025, Standard Deviation: 0.0036294981837272644\n",
      "PFT 3: Average chl value: 0.0063145700842142105, Standard Deviation: 0.0050837271846830845\n",
      "PFT 1: Average lai value: 0.0009154543513432145, Standard Deviation: 0.0019999693613499403\n",
      "PFT 2: Average lai value: 0.0008382137748412788, Standard Deviation: 0.002042969223111868\n",
      "PFT 3: Average lai value: 0.0010830465471372008, Standard Deviation: 0.0023843145463615656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 07\n",
      "\n",
      "Processing data for time: 08\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0029146866872906685, Standard Deviation: 0.004039015155285597\n",
      "PFT 2: Average chl value: 0.002565424656495452, Standard Deviation: 0.0038404115475714207\n",
      "PFT 3: Average chl value: 0.0060317665338516235, Standard Deviation: 0.004997005220502615\n",
      "PFT 1: Average lai value: 0.0009949168888852, Standard Deviation: 0.0022500280756503344\n",
      "PFT 2: Average lai value: 0.0010031139245256782, Standard Deviation: 0.0030419749673455954\n",
      "PFT 3: Average lai value: 0.0009717097273096442, Standard Deviation: 0.0021009768825024366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 08\n",
      "\n",
      "Processing data for time: 09\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.002276134677231312, Standard Deviation: 0.0035408535040915012\n",
      "PFT 2: Average chl value: 0.0019114139722660184, Standard Deviation: 0.0032134316861629486\n",
      "PFT 3: Average chl value: 0.005371856968849897, Standard Deviation: 0.004833210725337267\n",
      "PFT 1: Average lai value: 0.0007076486945152283, Standard Deviation: 0.0015882754232734442\n",
      "PFT 2: Average lai value: 0.0006653843447566032, Standard Deviation: 0.0017371834255754948\n",
      "PFT 3: Average lai value: 0.0007945008110255003, Standard Deviation: 0.0015643204096704721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 09\n",
      "\n",
      "Processing data for time: 10\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0023361078929156065, Standard Deviation: 0.0037085101939737797\n",
      "PFT 2: Average chl value: 0.001702791778370738, Standard Deviation: 0.00311901792883873\n",
      "PFT 3: Average chl value: 0.0051617128774523735, Standard Deviation: 0.004826975986361504\n",
      "PFT 1: Average lai value: 0.0007519208593294024, Standard Deviation: 0.001996516715735197\n",
      "PFT 2: Average lai value: 0.0007199300453066826, Standard Deviation: 0.002165879588574171\n",
      "PFT 3: Average lai value: 0.0006915520643815398, Standard Deviation: 0.0012348892632871866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 10\n",
      "\n",
      "Processing data for time: 11\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0018413340440019965, Standard Deviation: 0.00317760999314487\n",
      "PFT 2: Average chl value: 0.001468524569645524, Standard Deviation: 0.002834819722920656\n",
      "PFT 3: Average chl value: 0.0045112259685993195, Standard Deviation: 0.004600367974489927\n",
      "PFT 1: Average lai value: 0.0005984633462503552, Standard Deviation: 0.0010297073749825358\n",
      "PFT 2: Average lai value: 0.0005746592069044709, Standard Deviation: 0.0010463644284754992\n",
      "PFT 3: Average lai value: 0.000608137110248208, Standard Deviation: 0.000779853027779609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 11\n",
      "\n",
      "Processing data for time: 12\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0022041217889636755, Standard Deviation: 0.0035982111003249884\n",
      "PFT 2: Average chl value: 0.0017382991500198841, Standard Deviation: 0.003324772696942091\n",
      "PFT 3: Average chl value: 0.005135365296155214, Standard Deviation: 0.004785308614373207\n",
      "PFT 1: Average lai value: 0.0007330116932280362, Standard Deviation: 0.001340948510915041\n",
      "PFT 2: Average lai value: 0.0007098929490894079, Standard Deviation: 0.00137589150108397\n",
      "PFT 3: Average lai value: 0.0008151970105245709, Standard Deviation: 0.001607240061275661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 458, 492)\n",
      "(458, 492)\n",
      "Data processing and saving completed for time: 12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3266203/1009613715.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Define the range of times from 00 to 12\n",
    "times = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "# Given dates\n",
    "dates = [\"2022-02-24T00:00:00.000000\", \"2022-02-28T00:00:00.000000\", \"2022-03-08T00:00:00.000000\",\n",
    "         \"2022-03-16T00:00:00.000000\", \"2022-03-22T00:00:00.000000\", \"2022-04-05T00:00:00.000000\",\n",
    "         \"2022-04-12T00:00:00.000000\", \"2022-04-20T00:00:00.000000\", \"2022-04-29T00:00:00.000000\",\n",
    "         \"2022-05-03T00:00:00.000000\", \"2022-05-11T00:00:00.000000\", \"2022-05-17T00:00:00.000000\",\n",
    "         \"2022-05-29T00:00:00.000000\"]\n",
    "\n",
    "# Extract dates without times\n",
    "dates_without_times = [date.split('T')[0] for date in dates]\n",
    "\n",
    "# Loop over times\n",
    "for time in times:\n",
    "\n",
    "    # Informative message: Loading datasets for the current time\n",
    "    print(f'Processing data for time: {time}')\n",
    "    \n",
    "    # Load chl and PFT datasets for the current time\n",
    "    chl_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/pro_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    lai_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/cbc_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    #lma_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lma_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    pft_ds = xr.open_dataset(f'../California_Vegetation_WHRTYPE_Dangermond/output_latlon.nc')  # Update the PFT dataset filename\n",
    "    \n",
    "    # Informative message: Extracting data from the loaded datasets\n",
    "    print('Extracting data from the loaded datasets...')\n",
    "    \n",
    "    # Extract chl values and PFT data\n",
    "    chl_values = chl_ds['pro'].values\n",
    "    lai_values = lai_ds['cbc'].values\n",
    "    #lma_values = lma_ds['lma'].values\n",
    "    pft_values = pft_ds['Band1'].values  # Assuming PFT values are stored in Band1 variable\n",
    "    \n",
    "    # Define PFT categories (2, 3, 4)\n",
    "    pft_categories = [2, 3, 4]\n",
    "    \n",
    "    # Create a mask for PFT categories\n",
    "    pft_mask = np.isin(pft_values, pft_categories)\n",
    "    \n",
    "    # Ensure chl_values and pft_mask have the same shape\n",
    "    masked_chl_values = np.ma.masked_where(~pft_mask[:, :], chl_values[0, :, :])\n",
    "    masked_lai_values = np.ma.masked_where(~pft_mask[:, :], lai_values[0, :, :])\n",
    "    #masked_lma_values = np.ma.masked_where(~pft_mask[:, :], lma_values[0, :, :])\n",
    "    \n",
    "    # Calculate average chl value per PFT\n",
    "    average_chl_per_pft = []\n",
    "    std_chl_per_pft = []\n",
    "    average_lai_per_pft = []\n",
    "    std_lai_per_pft = []\n",
    "    #average_lma_per_pft = []\n",
    "    #std_lma_per_pft = []\n",
    "    for pft_category in pft_categories:\n",
    "        # chl\n",
    "        pft_chl_values = masked_chl_values[pft_values[:, :] == pft_category]\n",
    "        average_chl = np.nanmean(pft_chl_values)\n",
    "        std_chl = np.nanstd(pft_chl_values)\n",
    "        average_chl_per_pft.append(average_chl)\n",
    "        std_chl_per_pft.append(std_chl)\n",
    "        \n",
    "        # lai\n",
    "        pft_lai_values = masked_lai_values[pft_values[:, :] == pft_category]\n",
    "        average_lai = np.nanmean(pft_lai_values)\n",
    "        std_lai = np.nanstd(pft_lai_values)\n",
    "        average_lai_per_pft.append(average_lai)\n",
    "        std_lai_per_pft.append(std_lai)\n",
    "        \n",
    "        # lma\n",
    "        #pft_lma_values = masked_lma_values[pft_values[:, :] == pft_category]\n",
    "        #pft_lma_values = pft_lma_values[(~np.isnan(pft_lma_values)) & (pft_lma_values != 0)]\n",
    "        #average_lma = np.nanmean(pft_lma_values)\n",
    "        #std_lma = np.nanstd(pft_lma_values)\n",
    "        #average_lma_per_pft.append(average_lma)\n",
    "        #std_lma_per_pft.append(std_lma)\n",
    "    \n",
    "    # Print average and standard deviation chl values per PFT\n",
    "    for idx, (avg_chl, std_chl) in enumerate(zip(average_chl_per_pft, std_chl_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average chl value: {avg_chl}, Standard Deviation: {std_chl}')\n",
    "\n",
    "    # Print average and standard deviation lai values per PFT\n",
    "    for idx, (avg_lai, std_lai) in enumerate(zip(average_lai_per_pft, std_lai_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average lai value: {avg_lai}, Standard Deviation: {std_lai}')\n",
    "\n",
    "    # Print average and standard deviation lma values per PFT\n",
    "    #for idx, (avg_lma, std_lma) in enumerate(zip(average_lma_per_pft, std_lma_per_pft)):\n",
    "    #    print(f'PFT {pft_categories[idx]-1}: Average lma value: {avg_lma}, Standard Deviation: {std_lma}')\n",
    "\n",
    "    # Optionally, save the new chl map with masked values\n",
    "    # chl_ds['chl'][:] = masked_chl_values\n",
    "    # chl_ds.to_netcdf('masked_chl_aviris_dangermond.nc')\n",
    "\n",
    "    # Create a new chl map with average values per PFT\n",
    "    new_chl_values = np.zeros_like(chl_values[0,:,:])\n",
    "    new_std_chl_values = np.zeros_like(chl_values[0,:,:])\n",
    "    new_lai_values = np.zeros_like(lai_values[0,:,:])\n",
    "    new_std_lai_values = np.zeros_like(lai_values[0,:,:])\n",
    "    #new_lma_values = np.zeros_like(lma_values[0,:,:])\n",
    "    #new_std_lma_values = np.zeros_like(lma_values[0,:,:])\n",
    "\n",
    "\n",
    "    # Creating plots for all PFTs for chl\n",
    "    #plt.figure()\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size\n",
    "    colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)[:, :]\n",
    "        new_chl_values[mask] = average_chl_per_pft[idx]\n",
    "        new_std_chl_values[mask] = std_chl_per_pft[idx]\n",
    "        #new_lai_values[mask] = average_lai_per_pft[idx]\n",
    "        #new_std_lai_values[mask] = std_lai_per_pft[idx]\n",
    "        #new_lma_values[mask] = average_lma_per_pft[idx]\n",
    "        #new_std_lma_values[mask] = std_lma_per_pft[idx]\n",
    "\n",
    "        # Extract chl values for the current PFT category\n",
    "        chl_for_pft = masked_chl_values[pft_values == pft_category].compressed()\n",
    "        avg_chl = average_chl_per_pft[idx]\n",
    "        std_chl = std_chl_per_pft[idx]\n",
    "\n",
    "        # Create a histogram for chl values with transparency\n",
    "        plt.hist(chl_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "\n",
    "        # Add a vertical line for the average\n",
    "        plt.axvline(avg_chl, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Prepare text for the legend\n",
    "        avg_std_text = f'{avg_chl:.2f} ± {std_chl:.2f}'\n",
    "        legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "    plt.title(f'Combined CHL Distribution ({dates_without_times[int(time)]})', fontsize=18)\n",
    "    plt.xlabel(r'PRO Value (g.cm$^{-2}$)', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.ylim(0, 0.015)  # Set y-axis limits\n",
    "    plt.xlim(0, 20)  # Set y-axis limits\n",
    "    plt.legend(legend_labels, fontsize=14)  # Increase legend fontsize\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick label fontsize\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick label fontsize\n",
    "\n",
    "    # Save the combined plot as a PNG file\n",
    "    #plt.savefig(f'combined_chl_histogram_time_{time}.png',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Creating plots for all PFTs for lai\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size\n",
    "    colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)[:, :]\n",
    "        #new_chl_values[mask] = average_chl_per_pft[idx]\n",
    "        #new_std_chl_values[mask] = std_chl_per_pft[idx]\n",
    "        new_lai_values[mask] = average_lai_per_pft[idx]\n",
    "        new_std_lai_values[mask] = std_lai_per_pft[idx]\n",
    "        #new_lma_values[mask] = average_lma_per_pft[idx]\n",
    "        #new_std_lma_values[mask] = std_lma_per_pft[idx]\n",
    "\n",
    "        # Extract chl values for the current PFT category\n",
    "        lai_for_pft = masked_lai_values[pft_values == pft_category].compressed()\n",
    "        avg_lai = average_lai_per_pft[idx]\n",
    "        std_lai = std_lai_per_pft[idx]\n",
    "\n",
    "        # Create a histogram for chl values with transparency\n",
    "        plt.hist(lai_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "\n",
    "        # Add a vertical line for the average\n",
    "        plt.axvline(avg_lai, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Prepare text for the legend\n",
    "        avg_std_text = f'{avg_lai:.2f} ± {std_lai:.2f}'\n",
    "        legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "    plt.title(f'Combined LAI Distribution ({dates_without_times[int(time)]})', fontsize=18)\n",
    "    plt.xlabel(r'CBC Value (g.cm$^{-2}$)', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.ylim(0, 0.035)  # Set y-axis limits\n",
    "    plt.xlim(0, 7.5)  # Set y-axis limits\n",
    "    plt.legend(legend_labels, fontsize=14)  # Increase legend fontsize\n",
    "    plt.xticks(fontsize=14)  # Increase x-axis tick label fontsize\n",
    "    plt.yticks(fontsize=14)  # Increase y-axis tick label fontsize\n",
    "\n",
    "    # Save the combined plot as a PNG file\n",
    "    #plt.savefig(f'combined_lai_histogram_time_{time}.png')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "\n",
    "    # Create new xarray DataArrays for chl and std\n",
    "    new_chl_da = xr.DataArray(new_chl_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': chl_ds['time'], 'lat': chl_ds['lat'], 'lon': chl_ds['lon']})\n",
    "    new_std_chl_da = xr.DataArray(new_std_chl_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': chl_ds['time'], 'lat': chl_ds['lat'], 'lon': chl_ds['lon']})\n",
    "\n",
    "\n",
    "    # Replace zeros by NaN in new maps\n",
    "    new_chl_da = new_chl_da.where(new_chl_da != 0, np.nan)\n",
    "    new_std_chl_da = new_std_chl_da.where(new_std_chl_da != 0, np.nan)\n",
    "\n",
    "    # Create a new xarray Dataset with chl and std DataArrays\n",
    "    new_chl_data = {'pro': new_chl_da, 'std': new_std_chl_da}\n",
    "    new_chl_ds = xr.Dataset(new_chl_data)\n",
    "    \n",
    "\n",
    "    # Save the new chl map with masked values and standard deviation to a NetCDF file\n",
    "    new_chl_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_pro_aviris_dangermond_time_{time}.nc')\n",
    "\n",
    "    print(lai_values.shape)\n",
    "    print(new_lai_values.shape)\n",
    "    # Create new xarray DataArrays for lai and std\n",
    "    #new_lai_da = xr.DataArray(new_lai_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': lai_ds['time'], 'lat': lai_ds['lat'], 'lon': lai_ds['lon']})\n",
    "    #ai_values = np.clip(lai_values, 1e-1, 20.)  # Clip values between 0.1 and max_lai\n",
    "    new_lai_values = lai_values[0,:,:]*(new_std_lai_values/new_std_lai_values)\n",
    "    \n",
    "    new_lai_da = xr.DataArray(new_lai_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': lai_ds['time'], 'lat': lai_ds['lat'], 'lon': lai_ds['lon']})\n",
    "    new_std_lai_da = xr.DataArray(new_std_lai_values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': lai_ds['time'], 'lat': lai_ds['lat'], 'lon': lai_ds['lon']})\n",
    "    \n",
    "    # Replace zeros by NaN in new maps\n",
    "    new_lai_da = new_lai_da.where(new_lai_da != 0, np.nan)\n",
    "    new_lai_da = new_lai_da.where(~np.isnan(new_lai_da), np.nan)\n",
    "\n",
    "    new_std_lai_da = new_std_lai_da.where(new_std_lai_da != 0, np.nan)\n",
    "\n",
    "    # Create a new xarray Dataset with lai and std DataArrays\n",
    "    new_lai_data = {'cbc': new_lai_da, 'std': new_std_lai_da}\n",
    "    new_lai_ds = xr.Dataset(new_lai_data)\n",
    "    \n",
    "    # Save the new lai map with masked values and standard deviation to a NetCDF file\n",
    "    new_lai_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_cbc_aviris_dangermond_time_{time}.nc')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Informative message: Data processing and saving completed for the current time\n",
    "    print(f'Data processing and saving completed for time: {time}\\n')\n",
    "\n",
    "    # Close the opened datasets\n",
    "    chl_ds.close()\n",
    "    lai_ds.close()\n",
    "    #lma_ds.close()\n",
    "    pft_ds.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b2b34",
   "metadata": {},
   "source": [
    "### Generate PFT average files separate by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d77285cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for time: 00\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 46.729957580566406, Standard Deviation: 24.14640235900879\n",
      "PFT 2: Average chl value: 41.99604415893555, Standard Deviation: 23.10335922241211\n",
      "PFT 3: Average chl value: 61.09103012084961, Standard Deviation: 21.684953689575195\n",
      "PFT 1: Average lai value: 3.1625101566314697, Standard Deviation: 4.1916093826293945\n",
      "PFT 2: Average lai value: 2.9527974128723145, Standard Deviation: 4.051224231719971\n",
      "PFT 3: Average lai value: 5.522914886474609, Standard Deviation: 5.532774925231934\n",
      "PFT 1: Average lma value: 0.007947982288897038, Standard Deviation: 0.010108904913067818\n",
      "PFT 2: Average lma value: 0.00682315556332469, Standard Deviation: 0.009396327659487724\n",
      "PFT 3: Average lma value: 0.015052175149321556, Standard Deviation: 0.013613208197057247\n",
      "Data processing and saving completed for time: 00\n",
      "\n",
      "Processing data for time: 01\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 43.979766845703125, Standard Deviation: 24.082256317138672\n",
      "PFT 2: Average chl value: 39.70149612426758, Standard Deviation: 22.693452835083008\n",
      "PFT 3: Average chl value: 59.3845100402832, Standard Deviation: 22.051124572753906\n",
      "PFT 1: Average lai value: 2.801231861114502, Standard Deviation: 3.8114562034606934\n",
      "PFT 2: Average lai value: 2.6050188541412354, Standard Deviation: 3.6731910705566406\n",
      "PFT 3: Average lai value: 4.929548740386963, Standard Deviation: 4.960460186004639\n",
      "PFT 1: Average lma value: 0.0067498404532670975, Standard Deviation: 0.008963307365775108\n",
      "PFT 2: Average lma value: 0.005778426304459572, Standard Deviation: 0.00836808793246746\n",
      "PFT 3: Average lma value: 0.013094979338347912, Standard Deviation: 0.01219993643462658\n",
      "Data processing and saving completed for time: 01\n",
      "\n",
      "Processing data for time: 02\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 44.33891677856445, Standard Deviation: 23.780895233154297\n",
      "PFT 2: Average chl value: 38.91999816894531, Standard Deviation: 22.307130813598633\n",
      "PFT 3: Average chl value: 58.3569221496582, Standard Deviation: 21.672563552856445\n",
      "PFT 1: Average lai value: 2.861719846725464, Standard Deviation: 3.898144483566284\n",
      "PFT 2: Average lai value: 2.580091714859009, Standard Deviation: 3.7050416469573975\n",
      "PFT 3: Average lai value: 5.027500629425049, Standard Deviation: 5.013463497161865\n",
      "PFT 1: Average lma value: 0.007191690616309643, Standard Deviation: 0.00894811749458313\n",
      "PFT 2: Average lma value: 0.006057251710444689, Standard Deviation: 0.008076006546616554\n",
      "PFT 3: Average lma value: 0.013003963977098465, Standard Deviation: 0.011609423905611038\n",
      "Data processing and saving completed for time: 02\n",
      "\n",
      "Processing data for time: 03\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 35.97517395019531, Standard Deviation: 22.465438842773438\n",
      "PFT 2: Average chl value: 32.30778884887695, Standard Deviation: 20.475276947021484\n",
      "PFT 3: Average chl value: 52.737125396728516, Standard Deviation: 22.575523376464844\n",
      "PFT 1: Average lai value: 2.337899684906006, Standard Deviation: 3.1660783290863037\n",
      "PFT 2: Average lai value: 2.2149858474731445, Standard Deviation: 3.1408309936523438\n",
      "PFT 3: Average lai value: 4.379950523376465, Standard Deviation: 4.262785911560059\n",
      "PFT 1: Average lma value: 0.005545346532016993, Standard Deviation: 0.006928735412657261\n",
      "PFT 2: Average lma value: 0.00491532776504755, Standard Deviation: 0.006408201064914465\n",
      "PFT 3: Average lma value: 0.010968517512083054, Standard Deviation: 0.009610921144485474\n",
      "Data processing and saving completed for time: 03\n",
      "\n",
      "Processing data for time: 04\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 44.33628463745117, Standard Deviation: 23.3028564453125\n",
      "PFT 2: Average chl value: 39.12870788574219, Standard Deviation: 22.04659080505371\n",
      "PFT 3: Average chl value: 57.25511932373047, Standard Deviation: 21.361536026000977\n",
      "PFT 1: Average lai value: 2.5401611328125, Standard Deviation: 3.725193500518799\n",
      "PFT 2: Average lai value: 2.345837116241455, Standard Deviation: 3.6323347091674805\n",
      "PFT 3: Average lai value: 4.758341312408447, Standard Deviation: 4.845849514007568\n",
      "PFT 1: Average lma value: 0.006876408588141203, Standard Deviation: 0.00825174618512392\n",
      "PFT 2: Average lma value: 0.005905728321522474, Standard Deviation: 0.007302793674170971\n",
      "PFT 3: Average lma value: 0.011793714016675949, Standard Deviation: 0.010475073009729385\n",
      "Data processing and saving completed for time: 04\n",
      "\n",
      "Processing data for time: 05\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 33.892906188964844, Standard Deviation: 20.589265823364258\n",
      "PFT 2: Average chl value: 29.334959030151367, Standard Deviation: 18.320785522460938\n",
      "PFT 3: Average chl value: 51.1032600402832, Standard Deviation: 21.552085876464844\n",
      "PFT 1: Average lai value: 2.0008904933929443, Standard Deviation: 2.5605907440185547\n",
      "PFT 2: Average lai value: 1.9591240882873535, Standard Deviation: 2.7923312187194824\n",
      "PFT 3: Average lai value: 3.8213491439819336, Standard Deviation: 3.4363958835601807\n",
      "PFT 1: Average lma value: 0.005179934669286013, Standard Deviation: 0.0057813432067632675\n",
      "PFT 2: Average lma value: 0.0047063580714166164, Standard Deviation: 0.005884181242436171\n",
      "PFT 3: Average lma value: 0.009872839786112309, Standard Deviation: 0.00783076137304306\n",
      "Data processing and saving completed for time: 05\n",
      "\n",
      "Processing data for time: 06\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 29.26422119140625, Standard Deviation: 20.33661651611328\n",
      "PFT 2: Average chl value: 24.155784606933594, Standard Deviation: 17.312219619750977\n",
      "PFT 3: Average chl value: 45.61111831665039, Standard Deviation: 22.502614974975586\n",
      "PFT 1: Average lai value: 1.7186317443847656, Standard Deviation: 2.4869611263275146\n",
      "PFT 2: Average lai value: 1.5307230949401855, Standard Deviation: 2.3183906078338623\n",
      "PFT 3: Average lai value: 3.257086753845215, Standard Deviation: 3.055248260498047\n",
      "PFT 1: Average lma value: 0.004642193671315908, Standard Deviation: 0.005771165248006582\n",
      "PFT 2: Average lma value: 0.003921342547982931, Standard Deviation: 0.005028424318879843\n",
      "PFT 3: Average lma value: 0.008790964260697365, Standard Deviation: 0.00712042348459363\n",
      "Data processing and saving completed for time: 06\n",
      "\n",
      "Processing data for time: 07\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 24.52532196044922, Standard Deviation: 17.936996459960938\n",
      "PFT 2: Average chl value: 20.45149803161621, Standard Deviation: 15.489215850830078\n",
      "PFT 3: Average chl value: 38.418060302734375, Standard Deviation: 20.700109481811523\n",
      "PFT 1: Average lai value: 1.2239078283309937, Standard Deviation: 1.7350810766220093\n",
      "PFT 2: Average lai value: 1.116944432258606, Standard Deviation: 1.801390528678894\n",
      "PFT 3: Average lai value: 2.3476502895355225, Standard Deviation: 2.172451972961426\n",
      "PFT 1: Average lma value: 0.003924593795090914, Standard Deviation: 0.004614424426108599\n",
      "PFT 2: Average lma value: 0.003431732766330242, Standard Deviation: 0.004296206869184971\n",
      "PFT 3: Average lma value: 0.007397616747766733, Standard Deviation: 0.0057173920795321465\n",
      "Data processing and saving completed for time: 07\n",
      "\n",
      "Processing data for time: 08\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 24.886810302734375, Standard Deviation: 17.368656158447266\n",
      "PFT 2: Average chl value: 20.953990936279297, Standard Deviation: 15.787999153137207\n",
      "PFT 3: Average chl value: 37.59053421020508, Standard Deviation: 19.639442443847656\n",
      "PFT 1: Average lai value: 1.2465170621871948, Standard Deviation: 1.8182626962661743\n",
      "PFT 2: Average lai value: 1.2171220779418945, Standard Deviation: 2.294240713119507\n",
      "PFT 3: Average lai value: 2.3000566959381104, Standard Deviation: 2.1096510887145996\n",
      "PFT 1: Average lma value: 0.00390960369259119, Standard Deviation: 0.004736128728836775\n",
      "PFT 2: Average lma value: 0.003568538697436452, Standard Deviation: 0.005376187153160572\n",
      "PFT 3: Average lma value: 0.007003475911915302, Standard Deviation: 0.00549296336248517\n",
      "Data processing and saving completed for time: 08\n",
      "\n",
      "Processing data for time: 09\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 18.28829002380371, Standard Deviation: 15.582550048828125\n",
      "PFT 2: Average chl value: 14.814322471618652, Standard Deviation: 12.176765441894531\n",
      "PFT 3: Average chl value: 31.746946334838867, Standard Deviation: 19.475624084472656\n",
      "PFT 1: Average lai value: 0.8554477095603943, Standard Deviation: 1.3896745443344116\n",
      "PFT 2: Average lai value: 0.7296227216720581, Standard Deviation: 1.4056288003921509\n",
      "PFT 3: Average lai value: 1.8511911630630493, Standard Deviation: 1.7509791851043701\n",
      "PFT 1: Average lma value: 0.00298378337174654, Standard Deviation: 0.004029806703329086\n",
      "PFT 2: Average lma value: 0.0025767982006073, Standard Deviation: 0.003838189411908388\n",
      "PFT 3: Average lma value: 0.006166358012706041, Standard Deviation: 0.005133980419486761\n",
      "Data processing and saving completed for time: 09\n",
      "\n",
      "Processing data for time: 10\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 17.539751052856445, Standard Deviation: 15.556224822998047\n",
      "PFT 2: Average chl value: 12.771330833435059, Standard Deviation: 12.414155006408691\n",
      "PFT 3: Average chl value: 29.05889320373535, Standard Deviation: 18.78983497619629\n",
      "PFT 1: Average lai value: 0.86321622133255, Standard Deviation: 1.6881896257400513\n",
      "PFT 2: Average lai value: 0.6527736186981201, Standard Deviation: 1.5737149715423584\n",
      "PFT 3: Average lai value: 1.6189684867858887, Standard Deviation: 1.591029405593872\n",
      "PFT 1: Average lma value: 0.0030880288686603308, Standard Deviation: 0.0044477591291069984\n",
      "PFT 2: Average lma value: 0.0024227218236774206, Standard Deviation: 0.004062011372298002\n",
      "PFT 3: Average lma value: 0.005853264592587948, Standard Deviation: 0.005022504832595587\n",
      "Data processing and saving completed for time: 10\n",
      "\n",
      "Processing data for time: 11\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 14.704618453979492, Standard Deviation: 13.157190322875977\n",
      "PFT 2: Average chl value: 10.984109878540039, Standard Deviation: 10.957596778869629\n",
      "PFT 3: Average chl value: 25.19135093688965, Standard Deviation: 17.3702392578125\n",
      "PFT 1: Average lai value: 0.6348601579666138, Standard Deviation: 1.0916554927825928\n",
      "PFT 2: Average lai value: 0.5095308423042297, Standard Deviation: 1.0565277338027954\n",
      "PFT 3: Average lai value: 1.433714509010315, Standard Deviation: 1.4804470539093018\n",
      "PFT 1: Average lma value: 0.0024397976230829954, Standard Deviation: 0.0034071665722876787\n",
      "PFT 2: Average lma value: 0.0020431841257959604, Standard Deviation: 0.0031012122053653\n",
      "PFT 3: Average lma value: 0.005119363311678171, Standard Deviation: 0.004693000111728907\n",
      "Data processing and saving completed for time: 11\n",
      "\n",
      "Processing data for time: 12\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 19.905723571777344, Standard Deviation: 15.388687133789062\n",
      "PFT 2: Average chl value: 15.963467597961426, Standard Deviation: 14.426827430725098\n",
      "PFT 3: Average chl value: 31.564367294311523, Standard Deviation: 18.594419479370117\n",
      "PFT 1: Average lai value: 0.7717059850692749, Standard Deviation: 1.2931026220321655\n",
      "PFT 2: Average lai value: 0.6322526931762695, Standard Deviation: 1.3178621530532837\n",
      "PFT 3: Average lai value: 1.7237370014190674, Standard Deviation: 1.7811442613601685\n",
      "PFT 1: Average lma value: 0.0029371334239840508, Standard Deviation: 0.0039012765046209097\n",
      "PFT 2: Average lma value: 0.0024481918662786484, Standard Deviation: 0.003693418577313423\n",
      "PFT 3: Average lma value: 0.005950562190264463, Standard Deviation: 0.005097059067338705\n",
      "Data processing and saving completed for time: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Define the range of times from 00 to 12\n",
    "times = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "# Given dates\n",
    "dates = [\"2022-02-24T00:00:00.000000\", \"2022-02-28T00:00:00.000000\", \"2022-03-08T00:00:00.000000\",\n",
    "         \"2022-03-16T00:00:00.000000\", \"2022-03-22T00:00:00.000000\", \"2022-04-05T00:00:00.000000\",\n",
    "         \"2022-04-12T00:00:00.000000\", \"2022-04-20T00:00:00.000000\", \"2022-04-29T00:00:00.000000\",\n",
    "         \"2022-05-03T00:00:00.000000\", \"2022-05-11T00:00:00.000000\", \"2022-05-17T00:00:00.000000\",\n",
    "         \"2022-05-29T00:00:00.000000\"]\n",
    "\n",
    "# Extract dates without times\n",
    "dates_without_times = [date.split('T')[0] for date in dates]\n",
    "\n",
    "# Loop over times\n",
    "for time in times:\n",
    "\n",
    "    # Informative message: Loading datasets for the current time\n",
    "    print(f'Processing data for time: {time}')\n",
    "    \n",
    "    # Load chl and PFT datasets for the current time\n",
    "    chl_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/chl_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    lai_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lwc_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    lma_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lma_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    pft_ds = xr.open_dataset(f'../California_Vegetation_WHRTYPE_Dangermond/output_latlon.nc')  # Update the PFT dataset filename\n",
    "    \n",
    "    # Informative message: Extracting data from the loaded datasets\n",
    "    print('Extracting data from the loaded datasets...')\n",
    "    \n",
    "    # Extract chl values and PFT data\n",
    "    chl_values = chl_ds['chl'].values\n",
    "    lai_values = lai_ds['lwc'].values\n",
    "    lma_values = lma_ds['lma'].values\n",
    "    pft_values = pft_ds['Band1'].values  # Assuming PFT values are stored in Band1 variable\n",
    "    \n",
    "    # Define PFT categories (2, 3, 4)\n",
    "    pft_categories = [2, 3, 4]\n",
    "    \n",
    "    # Create a mask for PFT categories\n",
    "    pft_mask = np.isin(pft_values, pft_categories)\n",
    "    \n",
    "    # Ensure chl_values, lai_values, lma_values, and pft_mask have the same shape\n",
    "    masked_chl_values = np.ma.masked_where(~pft_mask[:, :], chl_values[0, :, :])\n",
    "    masked_lai_values = np.ma.masked_where(~pft_mask[:, :], lai_values[0, :, :])\n",
    "    masked_lma_values = np.ma.masked_where(~pft_mask[:, :], lma_values[0, :, :])\n",
    "    \n",
    "    # Calculate average and std values per PFT for chl, lai, and lma\n",
    "    average_chl_per_pft = []\n",
    "    std_chl_per_pft = []\n",
    "    average_lai_per_pft = []\n",
    "    std_lai_per_pft = []\n",
    "    average_lma_per_pft = []\n",
    "    std_lma_per_pft = []\n",
    "    for pft_category in pft_categories:\n",
    "        # chl\n",
    "        pft_chl_values = masked_chl_values[pft_values[:, :] == pft_category]\n",
    "        average_chl = np.nanmean(pft_chl_values)\n",
    "        std_chl = np.nanstd(pft_chl_values)\n",
    "        average_chl_per_pft.append(average_chl)\n",
    "        std_chl_per_pft.append(std_chl)\n",
    "        \n",
    "        # lai\n",
    "        pft_lai_values = masked_lai_values[pft_values[:, :] == pft_category]\n",
    "        average_lai = np.nanmean(pft_lai_values)\n",
    "        std_lai = np.nanstd(pft_lai_values)\n",
    "        average_lai_per_pft.append(average_lai)\n",
    "        std_lai_per_pft.append(std_lai)\n",
    "        \n",
    "        # lma\n",
    "        pft_lma_values = masked_lma_values[pft_values[:, :] == pft_category]\n",
    "        pft_lma_values = pft_lma_values[(~np.isnan(pft_lma_values)) & (pft_lma_values != 0)]\n",
    "        average_lma = np.nanmean(pft_lma_values)\n",
    "        std_lma = np.nanstd(pft_lma_values)\n",
    "        average_lma_per_pft.append(average_lma)\n",
    "        std_lma_per_pft.append(std_lma)\n",
    "    \n",
    "    # Print average and standard deviation values per PFT\n",
    "    for idx, (avg_chl, std_chl) in enumerate(zip(average_chl_per_pft, std_chl_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average chl value: {avg_chl}, Standard Deviation: {std_chl}')\n",
    "\n",
    "    for idx, (avg_lai, std_lai) in enumerate(zip(average_lai_per_pft, std_lai_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average lai value: {avg_lai}, Standard Deviation: {std_lai}')\n",
    "\n",
    "    for idx, (avg_lma, std_lma) in enumerate(zip(average_lma_per_pft, std_lma_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx]-1}: Average lma value: {avg_lma}, Standard Deviation: {std_lma}')\n",
    "\n",
    "    # Create new values arrays for chl, lai, and lma\n",
    "    new_chl_values = np.zeros_like(chl_values[0,:,:])\n",
    "    new_std_chl_values = np.zeros_like(chl_values[0,:,:])\n",
    "    new_lai_values = np.zeros_like(lai_values[0,:,:])\n",
    "    new_std_lai_values = np.zeros_like(lai_values[0,:,:])\n",
    "    new_lma_values = np.zeros_like(lma_values[0,:,:])\n",
    "    new_std_lma_values = np.zeros_like(lma_values[0,:,:])\n",
    "\n",
    "    # Fill new values arrays with averages per PFT\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)[:, :]\n",
    "        new_chl_values[mask] = average_chl_per_pft[idx]\n",
    "        new_std_chl_values[mask] = std_chl_per_pft[idx]\n",
    "        new_lai_values[mask] = average_lai_per_pft[idx]\n",
    "        new_std_lai_values[mask] = std_lai_per_pft[idx]\n",
    "        new_lma_values[mask] = average_lma_per_pft[idx]\n",
    "        new_std_lma_values[mask] = std_lma_per_pft[idx]\n",
    "\n",
    "    # Create plots for all PFTs for chl, lai, and lma\n",
    "    for trait, values, new_values, new_std_values, label, y_lim, x_lim in zip(\n",
    "            ['chl', 'lai', 'lma'],\n",
    "            [masked_chl_values, masked_lai_values, masked_lma_values],\n",
    "            [new_chl_values, new_lai_values, new_lma_values],\n",
    "            [new_std_chl_values, new_std_lai_values, new_std_lma_values],\n",
    "            [r'CHL Value ($\\mu$g.cm$^{-2}$)', r'LAI Value (m$^{2}$.m$^{-2}$)', r'LMA Value (g.cm$^{-2}$)'],\n",
    "            [0.5, 1.0, 800],\n",
    "            [20, 7.5, 0.03]):\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        colors = ['g', 'b', 'r']\n",
    "        legend_labels = []\n",
    "\n",
    "        for idx, pft_category in enumerate(pft_categories):\n",
    "            mask = (pft_values == pft_category)[:, :]\n",
    "            trait_values_for_pft = values[pft_values == pft_category].compressed()\n",
    "            avg_trait = np.nanmean(trait_values_for_pft)\n",
    "            std_trait = np.nanstd(trait_values_for_pft)\n",
    "\n",
    "            plt.hist(trait_values_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "            plt.axvline(avg_trait, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "            avg_std_text = f'{avg_trait:.2f} ± {std_trait:.2f}'\n",
    "            legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "        plt.title(f'Combined {trait.upper()} Distribution ({dates_without_times[int(time)]})', fontsize=18)\n",
    "        plt.xlabel(label, fontsize=16)\n",
    "        plt.ylabel('Density', fontsize=16)\n",
    "        plt.ylim(0, y_lim)\n",
    "        plt.xlim(0, x_lim)\n",
    "        plt.legend(legend_labels, fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    # Create new xarray DataArrays for chl, lai, and lma\n",
    "    def create_dataarray(values, time, lat, lon):\n",
    "        da = xr.DataArray(values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': time, 'lat': lat, 'lon': lon})\n",
    "        da = da.where(da != 0, np.nan)\n",
    "        return da\n",
    "\n",
    "    new_chl_da = create_dataarray(new_chl_values, chl_ds['time'], chl_ds['lat'], chl_ds['lon'])\n",
    "    new_std_chl_da = create_dataarray(new_std_chl_values, chl_ds['time'], chl_ds['lat'], chl_ds['lon'])\n",
    "\n",
    "    new_lai_da = create_dataarray(new_lai_values, lai_ds['time'], lai_ds['lat'], lai_ds['lon'])\n",
    "    new_std_lai_da = create_dataarray(new_std_lai_values, lai_ds['time'], lai_ds['lat'], lai_ds['lon'])\n",
    "\n",
    "    new_lma_da = create_dataarray(new_lma_values, lma_ds['time'], lma_ds['lat'], lma_ds['lon'])\n",
    "    new_std_lma_da = create_dataarray(new_std_lma_values, lma_ds['time'], lma_ds['lat'], lma_ds['lon'])\n",
    "\n",
    "    # Create new xarray Datasets\n",
    "    new_chl_ds = xr.Dataset({'chl': new_chl_da, 'std': new_std_chl_da})\n",
    "    new_lai_ds = xr.Dataset({'lwc': new_lai_da, 'std': new_std_lai_da})\n",
    "    new_lma_ds = xr.Dataset({'lma': new_lma_da, 'std': new_std_lma_da})\n",
    "\n",
    "    # Save the new datasets to NetCDF files\n",
    "    new_chl_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_chl_aviris_dangermond_time_{time}.nc')\n",
    "    new_lai_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lwc_aviris_dangermond_time_{time}.nc')\n",
    "    new_lma_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lma_aviris_dangermond_time_{time}.nc')\n",
    "\n",
    "    # Informative message: Data processing and saving completed for the current time\n",
    "    print(f'Data processing and saving completed for time: {time}\\n')\n",
    "\n",
    "    # Close the opened datasets\n",
    "    chl_ds.close()\n",
    "    lai_ds.close()\n",
    "    lma_ds.close()\n",
    "    pft_ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abd3731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for time: 00\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0037749402690678835, Standard Deviation: 0.004777900874614716\n",
      "PFT 2: Average chl value: 0.003240694059059024, Standard Deviation: 0.00432511605322361\n",
      "PFT 3: Average chl value: 0.007597974967211485, Standard Deviation: 0.0058870441280305386\n",
      "PFT 1: Average lai value: 0.004173042252659798, Standard Deviation: 0.007828260771930218\n",
      "PFT 2: Average lai value: 0.0035824610386043787, Standard Deviation: 0.007319921627640724\n",
      "PFT 3: Average lai value: 0.007454197853803635, Standard Deviation: 0.010692716576159\n",
      "Data processing and saving completed for time: 00\n",
      "\n",
      "Processing data for time: 01\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.003352547064423561, Standard Deviation: 0.00452774902805686\n",
      "PFT 2: Average chl value: 0.002853008219972253, Standard Deviation: 0.004072333686053753\n",
      "PFT 3: Average chl value: 0.00705363554880023, Standard Deviation: 0.0057800025679171085\n",
      "PFT 1: Average lai value: 0.003397292923182249, Standard Deviation: 0.006799566093832254\n",
      "PFT 2: Average lai value: 0.002925417385995388, Standard Deviation: 0.006350627169013023\n",
      "PFT 3: Average lai value: 0.006041343789547682, Standard Deviation: 0.009441041387617588\n",
      "Data processing and saving completed for time: 01\n",
      "\n",
      "Processing data for time: 02\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0038975533097982407, Standard Deviation: 0.0047516063787043095\n",
      "PFT 2: Average chl value: 0.0033831472974270582, Standard Deviation: 0.004306357353925705\n",
      "PFT 3: Average chl value: 0.0076296767219901085, Standard Deviation: 0.005794881843030453\n",
      "PFT 1: Average lai value: 0.0032941377721726894, Standard Deviation: 0.006763093173503876\n",
      "PFT 2: Average lai value: 0.002674104878678918, Standard Deviation: 0.005923988297581673\n",
      "PFT 3: Average lai value: 0.005374286323785782, Standard Deviation: 0.008912402205169201\n",
      "Data processing and saving completed for time: 02\n",
      "\n",
      "Processing data for time: 03\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0036316080950200558, Standard Deviation: 0.004560751374810934\n",
      "PFT 2: Average chl value: 0.0031995773315429688, Standard Deviation: 0.004158773459494114\n",
      "PFT 3: Average chl value: 0.007487156894057989, Standard Deviation: 0.005719374865293503\n",
      "PFT 1: Average lai value: 0.0019137379713356495, Standard Deviation: 0.004488872364163399\n",
      "PFT 2: Average lai value: 0.0017157497350126505, Standard Deviation: 0.004157334566116333\n",
      "PFT 3: Average lai value: 0.00348135968670249, Standard Deviation: 0.0067891874350607395\n",
      "Data processing and saving completed for time: 03\n",
      "\n",
      "Processing data for time: 04\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.003882898483425379, Standard Deviation: 0.004586655180901289\n",
      "PFT 2: Average chl value: 0.003580323653295636, Standard Deviation: 0.0043063415214419365\n",
      "PFT 3: Average chl value: 0.007419775240123272, Standard Deviation: 0.005636432208120823\n",
      "PFT 1: Average lai value: 0.0029935103375464678, Standard Deviation: 0.006329220719635487\n",
      "PFT 2: Average lai value: 0.002325404202565551, Standard Deviation: 0.005254601128399372\n",
      "PFT 3: Average lai value: 0.004373938776552677, Standard Deviation: 0.007964866235852242\n",
      "Data processing and saving completed for time: 04\n",
      "\n",
      "Processing data for time: 05\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.003673505736514926, Standard Deviation: 0.0043962085619568825\n",
      "PFT 2: Average chl value: 0.0033783316612243652, Standard Deviation: 0.004091169219464064\n",
      "PFT 3: Average chl value: 0.007430673576891422, Standard Deviation: 0.005439236760139465\n",
      "PFT 1: Average lai value: 0.0015064289327710867, Standard Deviation: 0.0033408410381525755\n",
      "PFT 2: Average lai value: 0.0013280260609462857, Standard Deviation: 0.003519537625834346\n",
      "PFT 3: Average lai value: 0.00244216644205153, Standard Deviation: 0.0050758798606693745\n",
      "Data processing and saving completed for time: 05\n",
      "\n",
      "Processing data for time: 06\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.003380988957360387, Standard Deviation: 0.004389374516904354\n",
      "PFT 2: Average chl value: 0.0029149444308131933, Standard Deviation: 0.003936667460948229\n",
      "PFT 3: Average chl value: 0.0069860294461250305, Standard Deviation: 0.005423575174063444\n",
      "PFT 1: Average lai value: 0.001261204364709556, Standard Deviation: 0.0031422602478414774\n",
      "PFT 2: Average lai value: 0.0010063981171697378, Standard Deviation: 0.0026400580536574125\n",
      "PFT 3: Average lai value: 0.0018049349309876561, Standard Deviation: 0.0040515996515750885\n",
      "Data processing and saving completed for time: 06\n",
      "\n",
      "Processing data for time: 07\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0030091397929936647, Standard Deviation: 0.004042166285216808\n",
      "PFT 2: Average chl value: 0.0025935189332813025, Standard Deviation: 0.0036294981837272644\n",
      "PFT 3: Average chl value: 0.0063145700842142105, Standard Deviation: 0.0050837271846830845\n",
      "PFT 1: Average lai value: 0.0009154543513432145, Standard Deviation: 0.0019999693613499403\n",
      "PFT 2: Average lai value: 0.0008382137748412788, Standard Deviation: 0.002042969223111868\n",
      "PFT 3: Average lai value: 0.0010830465471372008, Standard Deviation: 0.0023843145463615656\n",
      "Data processing and saving completed for time: 07\n",
      "\n",
      "Processing data for time: 08\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0029146866872906685, Standard Deviation: 0.004039015155285597\n",
      "PFT 2: Average chl value: 0.002565424656495452, Standard Deviation: 0.0038404115475714207\n",
      "PFT 3: Average chl value: 0.0060317665338516235, Standard Deviation: 0.004997005220502615\n",
      "PFT 1: Average lai value: 0.0009949168888852, Standard Deviation: 0.0022500280756503344\n",
      "PFT 2: Average lai value: 0.0010031139245256782, Standard Deviation: 0.0030419749673455954\n",
      "PFT 3: Average lai value: 0.0009717097273096442, Standard Deviation: 0.0021009768825024366\n",
      "Data processing and saving completed for time: 08\n",
      "\n",
      "Processing data for time: 09\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.002276134677231312, Standard Deviation: 0.0035408535040915012\n",
      "PFT 2: Average chl value: 0.0019114139722660184, Standard Deviation: 0.0032134316861629486\n",
      "PFT 3: Average chl value: 0.005371856968849897, Standard Deviation: 0.004833210725337267\n",
      "PFT 1: Average lai value: 0.0007076486945152283, Standard Deviation: 0.0015882754232734442\n",
      "PFT 2: Average lai value: 0.0006653843447566032, Standard Deviation: 0.0017371834255754948\n",
      "PFT 3: Average lai value: 0.0007945008110255003, Standard Deviation: 0.0015643204096704721\n",
      "Data processing and saving completed for time: 09\n",
      "\n",
      "Processing data for time: 10\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0023361078929156065, Standard Deviation: 0.0037085101939737797\n",
      "PFT 2: Average chl value: 0.001702791778370738, Standard Deviation: 0.00311901792883873\n",
      "PFT 3: Average chl value: 0.0051617128774523735, Standard Deviation: 0.004826975986361504\n",
      "PFT 1: Average lai value: 0.0007519208593294024, Standard Deviation: 0.001996516715735197\n",
      "PFT 2: Average lai value: 0.0007199300453066826, Standard Deviation: 0.002165879588574171\n",
      "PFT 3: Average lai value: 0.0006915520643815398, Standard Deviation: 0.0012348892632871866\n",
      "Data processing and saving completed for time: 10\n",
      "\n",
      "Processing data for time: 11\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0018413340440019965, Standard Deviation: 0.00317760999314487\n",
      "PFT 2: Average chl value: 0.001468524569645524, Standard Deviation: 0.002834819722920656\n",
      "PFT 3: Average chl value: 0.0045112259685993195, Standard Deviation: 0.004600367974489927\n",
      "PFT 1: Average lai value: 0.0005984633462503552, Standard Deviation: 0.0010297073749825358\n",
      "PFT 2: Average lai value: 0.0005746592069044709, Standard Deviation: 0.0010463644284754992\n",
      "PFT 3: Average lai value: 0.000608137110248208, Standard Deviation: 0.000779853027779609\n",
      "Data processing and saving completed for time: 11\n",
      "\n",
      "Processing data for time: 12\n",
      "Extracting data from the loaded datasets...\n",
      "PFT 1: Average chl value: 0.0022041217889636755, Standard Deviation: 0.0035982111003249884\n",
      "PFT 2: Average chl value: 0.0017382991500198841, Standard Deviation: 0.003324772696942091\n",
      "PFT 3: Average chl value: 0.005135365296155214, Standard Deviation: 0.004785308614373207\n",
      "PFT 1: Average lai value: 0.0007330116932280362, Standard Deviation: 0.001340948510915041\n",
      "PFT 2: Average lai value: 0.0007098929490894079, Standard Deviation: 0.00137589150108397\n",
      "PFT 3: Average lai value: 0.0008151970105245709, Standard Deviation: 0.001607240061275661\n",
      "Data processing and saving completed for time: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Define the range of times from 00 to 12\n",
    "times = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "# Given dates\n",
    "dates = [\"2022-02-24T00:00:00.000000\", \"2022-02-28T00:00:00.000000\", \"2022-03-08T00:00:00.000000\",\n",
    "         \"2022-03-16T00:00:00.000000\", \"2022-03-22T00:00:00.000000\", \"2022-04-05T00:00:00.000000\",\n",
    "         \"2022-04-12T00:00:00.000000\", \"2022-04-20T00:00:00.000000\", \"2022-04-29T00:00:00.000000\",\n",
    "         \"2022-05-03T00:00:00.000000\", \"2022-05-11T00:00:00.000000\", \"2022-05-17T00:00:00.000000\",\n",
    "         \"2022-05-29T00:00:00.000000\"]\n",
    "\n",
    "# Extract dates without times\n",
    "dates_without_times = [date.split('T')[0] for date in dates]\n",
    "\n",
    "# Loop over times\n",
    "for time in times:\n",
    "\n",
    "    # Informative message: Loading datasets for the current time\n",
    "    print(f'Processing data for time: {time}')\n",
    "    \n",
    "    # Load chl and PFT datasets for the current time\n",
    "    chl_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/pro_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    lai_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/cbc_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    #lma_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lma_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    pft_ds = xr.open_dataset(f'../California_Vegetation_WHRTYPE_Dangermond/output_latlon.nc')  # Update the PFT dataset filename\n",
    "    \n",
    "    # Informative message: Extracting data from the loaded datasets\n",
    "    print('Extracting data from the loaded datasets...')\n",
    "    \n",
    "    # Extract chl values and PFT data\n",
    "    chl_values = chl_ds['pro'].values\n",
    "    lai_values = lai_ds['cbc'].values\n",
    "    #lma_values = lma_ds['lma'].values\n",
    "    pft_values = pft_ds['Band1'].values  # Assuming PFT values are stored in Band1 variable\n",
    "    \n",
    "    # Define PFT categories (2, 3, 4)\n",
    "    pft_categories = [2, 3, 4]\n",
    "    \n",
    "    # Create a mask for PFT categories\n",
    "    pft_mask = np.isin(pft_values, pft_categories)\n",
    "    \n",
    "    # Ensure chl_values, lai_values, lma_values, and pft_mask have the same shape\n",
    "    masked_chl_values = np.ma.masked_where(~pft_mask[:, :], chl_values[0, :, :])\n",
    "    masked_lai_values = np.ma.masked_where(~pft_mask[:, :], lai_values[0, :, :])\n",
    "    #masked_lma_values = np.ma.masked_where(~pft_mask[:, :], lma_values[0, :, :])\n",
    "    \n",
    "    # Calculate average and std values per PFT for chl, lai, and lma\n",
    "    average_chl_per_pft = []\n",
    "    std_chl_per_pft = []\n",
    "    average_lai_per_pft = []\n",
    "    std_lai_per_pft = []\n",
    "    #average_lma_per_pft = []\n",
    "    #std_lma_per_pft = []\n",
    "    for pft_category in pft_categories:\n",
    "        # chl\n",
    "        pft_chl_values = masked_chl_values[pft_values[:, :] == pft_category]\n",
    "        average_chl = np.nanmean(pft_chl_values)\n",
    "        std_chl = np.nanstd(pft_chl_values)\n",
    "        average_chl_per_pft.append(average_chl)\n",
    "        std_chl_per_pft.append(std_chl)\n",
    "        \n",
    "        # lai\n",
    "        pft_lai_values = masked_lai_values[pft_values[:, :] == pft_category]\n",
    "        average_lai = np.nanmean(pft_lai_values)\n",
    "        std_lai = np.nanstd(pft_lai_values)\n",
    "        average_lai_per_pft.append(average_lai)\n",
    "        std_lai_per_pft.append(std_lai)\n",
    "        \n",
    "        # lma\n",
    "        #pft_lma_values = masked_lma_values[pft_values[:, :] == pft_category]\n",
    "        #pft_lma_values = pft_lma_values[(~np.isnan(pft_lma_values)) & (pft_lma_values != 0)]\n",
    "        #average_lma = np.nanmean(pft_lma_values)\n",
    "        #std_lma = np.nanstd(pft_lma_values)\n",
    "        #average_lma_per_pft.append(average_lma)\n",
    "        #std_lma_per_pft.append(std_lma)\n",
    "    \n",
    "    # Print average and standard deviation values per PFT\n",
    "    for idx, (avg_chl, std_chl) in enumerate(zip(average_chl_per_pft, std_chl_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average chl value: {avg_chl}, Standard Deviation: {std_chl}')\n",
    "\n",
    "    for idx, (avg_lai, std_lai) in enumerate(zip(average_lai_per_pft, std_lai_per_pft)):\n",
    "        print(f'PFT {pft_categories[idx] -1 }: Average lai value: {avg_lai}, Standard Deviation: {std_lai}')\n",
    "\n",
    "    #for idx, (avg_lma, std_lma) in enumerate(zip(average_lma_per_pft, std_lma_per_pft)):\n",
    "    #    print(f'PFT {pft_categories[idx]-1}: Average lma value: {avg_lma}, Standard Deviation: {std_lma}')\n",
    "\n",
    "    # Create new values arrays for chl, lai, and lma\n",
    "    new_chl_values = np.zeros_like(chl_values[0,:,:])\n",
    "    new_std_chl_values = np.zeros_like(chl_values[0,:,:])\n",
    "    new_lai_values = np.zeros_like(lai_values[0,:,:])\n",
    "    new_std_lai_values = np.zeros_like(lai_values[0,:,:])\n",
    "    #new_lma_values = np.zeros_like(lma_values[0,:,:])\n",
    "    #new_std_lma_values = np.zeros_like(lma_values[0,:,:])\n",
    "\n",
    "    # Fill new values arrays with averages per PFT\n",
    "    for idx, pft_category in enumerate(pft_categories):\n",
    "        mask = (pft_values == pft_category)[:, :]\n",
    "        new_chl_values[mask] = average_chl_per_pft[idx]\n",
    "        new_std_chl_values[mask] = std_chl_per_pft[idx]\n",
    "        new_lai_values[mask] = average_lai_per_pft[idx]\n",
    "        new_std_lai_values[mask] = std_lai_per_pft[idx]\n",
    "        #new_lma_values[mask] = average_lma_per_pft[idx]\n",
    "        #new_std_lma_values[mask] = std_lma_per_pft[idx]\n",
    "\n",
    "    # Create plots for all PFTs for chl, lai, and lma\n",
    "    for trait, values, new_values, new_std_values, label, y_lim, x_lim in zip(\n",
    "            ['pro', 'cbc'],\n",
    "            [masked_chl_values, masked_lai_values],\n",
    "            [new_chl_values, new_lai_values],\n",
    "            [new_std_chl_values, new_std_lai_values],\n",
    "            [r'PRO Value (g.cm$^{-2}$)', r'CBC Value (g.cm$^{-2}$)'],\n",
    "            [0.5, 1.0],\n",
    "            [20, 7.5]):\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        colors = ['g', 'b', 'r']\n",
    "        legend_labels = []\n",
    "\n",
    "        for idx, pft_category in enumerate(pft_categories):\n",
    "            mask = (pft_values == pft_category)[:, :]\n",
    "            trait_values_for_pft = values[pft_values == pft_category].compressed()\n",
    "            avg_trait = np.nanmean(trait_values_for_pft)\n",
    "            std_trait = np.nanstd(trait_values_for_pft)\n",
    "\n",
    "            plt.hist(trait_values_for_pft, bins=30, density=True, alpha=0.5, color=colors[idx])\n",
    "            plt.axvline(avg_trait, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "            avg_std_text = f'{avg_trait:.2f} ± {std_trait:.2f}'\n",
    "            legend_labels.append(f'PFT {pft_category}: {avg_std_text}')\n",
    "\n",
    "        plt.title(f'Combined {trait.upper()} Distribution ({dates_without_times[int(time)]})', fontsize=18)\n",
    "        plt.xlabel(label, fontsize=16)\n",
    "        plt.ylabel('Density', fontsize=16)\n",
    "        plt.ylim(0, y_lim)\n",
    "        plt.xlim(0, x_lim)\n",
    "        plt.legend(legend_labels, fontsize=14)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    # Create new xarray DataArrays for chl, lai, and lma\n",
    "    def create_dataarray(values, time, lat, lon):\n",
    "        da = xr.DataArray(values[np.newaxis,:,:], dims=('time', 'lat', 'lon'), coords={'time': time, 'lat': lat, 'lon': lon})\n",
    "        da = da.where(da != 0, np.nan)\n",
    "        return da\n",
    "\n",
    "    new_chl_da = create_dataarray(new_chl_values, chl_ds['time'], chl_ds['lat'], chl_ds['lon'])\n",
    "    new_std_chl_da = create_dataarray(new_std_chl_values, chl_ds['time'], chl_ds['lat'], chl_ds['lon'])\n",
    "\n",
    "    new_lai_da = create_dataarray(new_lai_values, lai_ds['time'], lai_ds['lat'], lai_ds['lon'])\n",
    "    new_std_lai_da = create_dataarray(new_std_lai_values, lai_ds['time'], lai_ds['lat'], lai_ds['lon'])\n",
    "\n",
    "    #new_lma_da = create_dataarray(new_lma_values, lma_ds['time'], lma_ds['lat'], lma_ds['lon'])\n",
    "    #new_std_lma_da = create_dataarray(new_std_lma_values, lma_ds['time'], lma_ds['lat'], lma_ds['lon'])\n",
    "\n",
    "    # Create new xarray Datasets\n",
    "    new_chl_ds = xr.Dataset({'pro': new_chl_da, 'std': new_std_chl_da})\n",
    "    new_lai_ds = xr.Dataset({'cbc': new_lai_da, 'std': new_std_lai_da})\n",
    "    #new_lma_ds = xr.Dataset({'lma': new_lma_da, 'std': new_std_lma_da})\n",
    "\n",
    "    # Save the new datasets to NetCDF files\n",
    "    new_chl_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_pro_aviris_dangermond_time_{time}.nc')\n",
    "    new_lai_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_cbc_aviris_dangermond_time_{time}.nc')\n",
    "    #new_lma_ds.to_netcdf(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lma_aviris_dangermond_time_{time}.nc')\n",
    "\n",
    "    # Informative message: Data processing and saving completed for the current time\n",
    "    print(f'Data processing and saving completed for time: {time}\\n')\n",
    "\n",
    "    # Close the opened datasets\n",
    "    chl_ds.close()\n",
    "    lai_ds.close()\n",
    "    #lma_ds.close()\n",
    "    pft_ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c00bf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved as /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/combined_lma_histogram.gif\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Directory containing the PNG images\n",
    "image_directory = '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/'\n",
    "\n",
    "# Output GIF file name\n",
    "output_gif = '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/combined_lma_histogram.gif'\n",
    "\n",
    "# List of PNG files in the directory\n",
    "png_files = [f for f in os.listdir(image_directory) if f.startswith('combined_lma_histogram_time_') and f.endswith('.png')]\n",
    "png_files.sort()  # Sort the files in ascending order by filename\n",
    "\n",
    "# Create a list to store image frames\n",
    "frames = []\n",
    "\n",
    "# Open and append each PNG image to the frames list\n",
    "for png_file in png_files:\n",
    "    image_path = os.path.join(image_directory, png_file)\n",
    "    img = Image.open(image_path)\n",
    "    frames.append(img)\n",
    "\n",
    "# Save the frames as an animated GIF\n",
    "frames[0].save(output_gif, save_all=True, append_images=frames[1:], duration=500, loop=0)\n",
    "\n",
    "print(f'GIF saved as {output_gif}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73fe59b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved as /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/combined_chl_histogram.gif\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Directory containing the PNG images\n",
    "image_directory = '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/'\n",
    "\n",
    "# Output GIF file name\n",
    "output_gif = '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/combined_chl_histogram.gif'\n",
    "\n",
    "# List of PNG files in the directory\n",
    "png_files = [f for f in os.listdir(image_directory) if f.startswith('combined_chl_histogram_time_') and f.endswith('.png')]\n",
    "png_files.sort()  # Sort the files in ascending order by filename\n",
    "\n",
    "# Create a list to store image frames\n",
    "frames = []\n",
    "\n",
    "# Open and append each PNG image to the frames list\n",
    "for png_file in png_files:\n",
    "    image_path = os.path.join(image_directory, png_file)\n",
    "    img = Image.open(image_path)\n",
    "    frames.append(img)\n",
    "\n",
    "# Save the frames as an animated GIF\n",
    "frames[0].save(output_gif, save_all=True, append_images=frames[1:], duration=500, loop=0)\n",
    "\n",
    "print(f'GIF saved as {output_gif}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab1345ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for time: 00\n",
      "Processing data for time: 01\n",
      "Processing data for time: 02\n",
      "Processing data for time: 03\n",
      "Processing data for time: 04\n",
      "Processing data for time: 05\n",
      "Processing data for time: 06\n",
      "Processing data for time: 07\n",
      "Processing data for time: 08\n",
      "Processing data for time: 09\n",
      "Processing data for time: 10\n",
      "Processing data for time: 11\n",
      "Processing data for time: 12\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the range of times from 00 to 12\n",
    "times = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "# Define PFT categories\n",
    "pft_categories = [2, 3, 4]\n",
    "#pft_categories = [1, 2, 3]\n",
    "colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "\n",
    "# Initialize accumulators for each trait and PFT\n",
    "data_accumulator = {trait: {pft: [] for pft in pft_categories} for trait in ['chl', 'lwc', 'lma']}\n",
    "\n",
    "# Loop over times to aggregate data\n",
    "for time in times:\n",
    "    print(f'Processing data for time: {time}')\n",
    "\n",
    "    # Load datasets for the current time\n",
    "    chl_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/chl_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    lai_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lwc_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    lma_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lma_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    pft_ds = xr.open_dataset(f'../California_Vegetation_WHRTYPE_Dangermond/output_latlon.nc')\n",
    "\n",
    "    # Extract data\n",
    "    chl_values = chl_ds['chl'].values.flatten()\n",
    "    lai_values = lai_ds['lwc'].values.flatten()\n",
    "    #change units from g.cm-2 to g.m-2\n",
    "    lma_values = lma_ds['lma'].values.flatten()*100*100\n",
    "    pft_values = pft_ds['Band1'].values.flatten()\n",
    "\n",
    "    # Aggregate data for each PFT\n",
    "    for pft in pft_categories:\n",
    "        pft_mask = pft_values == pft\n",
    "        data_accumulator['chl'][pft].extend(chl_values[pft_mask])\n",
    "        data_accumulator['lwc'][pft].extend(lai_values[pft_mask])\n",
    "        data_accumulator['lma'][pft].extend(lma_values[pft_mask])\n",
    "\n",
    "# Function to plot time-averaged histogram per PFT for a given trait\n",
    "def plot_time_averaged_histogram(data_accumulator, trait, colors, pft_categories):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft in enumerate(pft_categories):\n",
    "        data = np.array(data_accumulator[trait][pft])\n",
    "        valid_data = data[~np.isnan(data)]  # Remove NaNs\n",
    "\n",
    "        # Exclude the extreme values\n",
    "        min_val = np.nanmin(valid_data)\n",
    "        max_val = np.nanmax(valid_data)\n",
    "        data_to_plot = valid_data[(valid_data > min_val) & (valid_data < max_val)]\n",
    "\n",
    "        # Calculate average and std\n",
    "        avg, std = np.nanmean(data_to_plot), np.nanstd(data_to_plot)\n",
    "\n",
    "        # Plot histogram with a log scale if it's LMA\n",
    "        if trait == 'lma':\n",
    "            plt.yscale('log')  # Set y-axis to log scale for LMA\n",
    "\n",
    "        plt.hist(data_to_plot, bins=30, color=colors[idx], alpha=0.5, density=True)\n",
    "        plt.axvline(avg, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Legend without units\n",
    "        legend_labels.append(f'PFT {pft-1}: {avg:.2f} ± {std:.2f}' if trait == 'lma' else f'PFT {pft-1}: {avg:.2f} ± {std:.2f}')\n",
    "\n",
    "    # Set units for x-axis label\n",
    "    unit = 'μg/cm²' if trait == 'chl' else ('mol/m²' if trait == 'lwc' else 'g/m²')\n",
    "    plt.title(f'Time-Averaged {trait.upper()} Distribution by PFT', fontsize=18)\n",
    "    plt.xlabel(f'{trait.upper()} Value ({unit})', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.legend(legend_labels, fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.savefig(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/time_averaged_{trait}_distribution_by_pft.png',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Plot for each trait\n",
    "for trait in ['chl', 'lwc', 'lma']:\n",
    "    plot_time_averaged_histogram(data_accumulator, trait, colors, pft_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdb24cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for time: 00\n",
      "Processing data for time: 01\n",
      "Processing data for time: 02\n",
      "Processing data for time: 03\n",
      "Processing data for time: 04\n",
      "Processing data for time: 05\n",
      "Processing data for time: 06\n",
      "Processing data for time: 07\n",
      "Processing data for time: 08\n",
      "Processing data for time: 09\n",
      "Processing data for time: 10\n",
      "Processing data for time: 11\n",
      "Processing data for time: 12\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the range of times from 00 to 12\n",
    "times = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "# Define PFT categories\n",
    "pft_categories = [2, 3, 4]\n",
    "#pft_categories = [1, 2, 3]\n",
    "colors = ['g', 'b', 'r']  # Colors for PFTs 2, 3, 4\n",
    "\n",
    "# Initialize accumulators for each trait and PFT\n",
    "data_accumulator = {trait: {pft: [] for pft in pft_categories} for trait in ['pro', 'cbc']}\n",
    "\n",
    "# Loop over times to aggregate data\n",
    "for time in times:\n",
    "    print(f'Processing data for time: {time}')\n",
    "\n",
    "    # Load datasets for the current time\n",
    "    chl_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/pro_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    lai_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/cbc_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    #lma_ds = xr.open_dataset(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/lma_aviris_dangermond_clima_fit_time_{time}_reg.nc')\n",
    "    pft_ds = xr.open_dataset(f'../California_Vegetation_WHRTYPE_Dangermond/output_latlon.nc')\n",
    "\n",
    "    # Extract data\n",
    "    chl_values = chl_ds['pro'].values.flatten()\n",
    "    lai_values = lai_ds['cbc'].values.flatten()\n",
    "    #change units from g.cm-2 to g.m-2\n",
    "    #lma_values = lma_ds['lma'].values.flatten()*100*100\n",
    "    pft_values = pft_ds['Band1'].values.flatten()\n",
    "\n",
    "    # Aggregate data for each PFT\n",
    "    for pft in pft_categories:\n",
    "        pft_mask = pft_values == pft\n",
    "        data_accumulator['pro'][pft].extend(chl_values[pft_mask])\n",
    "        data_accumulator['cbc'][pft].extend(lai_values[pft_mask])\n",
    "        #data_accumulator['lma'][pft].extend(lma_values[pft_mask])\n",
    "\n",
    "# Function to plot time-averaged histogram per PFT for a given trait\n",
    "def plot_time_averaged_histogram(data_accumulator, trait, colors, pft_categories):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    legend_labels = []\n",
    "\n",
    "    for idx, pft in enumerate(pft_categories):\n",
    "        data = np.array(data_accumulator[trait][pft])\n",
    "        valid_data = data[~np.isnan(data)]  # Remove NaNs\n",
    "\n",
    "        # Exclude the extreme values\n",
    "        min_val = np.nanmin(valid_data)\n",
    "        max_val = np.nanmax(valid_data)\n",
    "        data_to_plot = valid_data[(valid_data > min_val) & (valid_data < max_val)]\n",
    "\n",
    "        # Calculate average and std\n",
    "        avg, std = np.nanmean(data_to_plot), np.nanstd(data_to_plot)\n",
    "\n",
    "        # Plot histogram with a log scale if it's LMA\n",
    "        if trait == 'lma':\n",
    "            plt.yscale('log')  # Set y-axis to log scale for LMA\n",
    "\n",
    "        plt.hist(data_to_plot, bins=30, color=colors[idx], alpha=0.5, density=True)\n",
    "        plt.axvline(avg, color=colors[idx], linestyle='dashed', linewidth=1)\n",
    "\n",
    "        # Legend without units\n",
    "        legend_labels.append(f'PFT {pft-1}: {avg:.2f} ± {std:.2f}' if trait == 'lma' else f'PFT {pft-1}: {avg:.2f} ± {std:.2f}')\n",
    "\n",
    "    # Set units for x-axis label\n",
    "    unit = 'g/cm²'\n",
    "    plt.title(f'Time-Averaged {trait.upper()} Distribution by PFT', fontsize=18)\n",
    "    plt.xlabel(f'{trait.upper()} Value ({unit})', fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.legend(legend_labels, fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.savefig(f'/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/figures/clima_fit_prescribed_lai_ci/time_averaged_{trait}_distribution_by_pft.png',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Plot for each trait\n",
    "for trait in ['pro', 'cbc']:\n",
    "    plot_time_averaged_histogram(data_accumulator, trait, colors, pft_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f1aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: cdo timmean -selname,chl /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_chl_aviris_dangermond_clima_fit.nc /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/mean_masked_chl_aviris_dangermond_clima_fit.nc\n",
      "Executing: cdo timmean -selname,lwc /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lwc_aviris_dangermond_clima_fit.nc /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/mean_masked_lwc_aviris_dangermond_clima_fit.nc\n",
      "Executing: cdo timmean -selname,lma /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lma_aviris_dangermond_clima_fit.nc /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/mean_masked_lma_aviris_dangermond_clima_fit.nc\n",
      "All operations completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the input and output filenames\n",
    "input_files = [\n",
    "    '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_chl_aviris_dangermond_clima_fit.nc',\n",
    "    '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lwc_aviris_dangermond_clima_fit.nc',\n",
    "    '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_lma_aviris_dangermond_clima_fit.nc'\n",
    "]\n",
    "\n",
    "output_files = [\n",
    "    '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/mean_masked_chl_aviris_dangermond_clima_fit.nc',\n",
    "    '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/mean_masked_lwc_aviris_dangermond_clima_fit.nc',\n",
    "    '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/mean_masked_lma_aviris_dangermond_clima_fit.nc'\n",
    "]\n",
    "\n",
    "variables = ['chl', 'lwc', 'lma']\n",
    "\n",
    "# Loop through each file and perform the cdo timmean operation\n",
    "for input_file, output_file, variable in zip(input_files, output_files, variables):\n",
    "    command = f'cdo timmean -selname,{variable} {input_file} {output_file}'\n",
    "    print(f'Executing: {command}')\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "print('All operations completed successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea2288a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: cdo timmean -selname,pro /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_pro_aviris_dangermond_clima_fit.nc /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/mean_masked_pro_aviris_dangermond_clima_fit.nc\n",
      "Executing: cdo timmean -selname,cbc /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_cbc_aviris_dangermond_clima_fit.nc /net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/mean_masked_cbc_aviris_dangermond_clima_fit.nc\n",
      "All operations completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the input and output filenames\n",
    "input_files = [\n",
    "    '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_pro_aviris_dangermond_clima_fit.nc',\n",
    "    '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/masked_cbc_aviris_dangermond_clima_fit.nc'\n",
    "]\n",
    "\n",
    "output_files = [\n",
    "    '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/mean_masked_pro_aviris_dangermond_clima_fit.nc',\n",
    "    '/net/fluo/data3/data/FluoData1/students/renato/aviris_dangermond/traits/datasets/clima_fit_prescribed_lai_ci/mean_masked_cbc_aviris_dangermond_clima_fit.nc'\n",
    "]\n",
    "\n",
    "variables = ['pro', 'cbc']\n",
    "\n",
    "# Loop through each file and perform the cdo timmean operation\n",
    "for input_file, output_file, variable in zip(input_files, output_files, variables):\n",
    "    command = f'cdo timmean -selname,{variable} {input_file} {output_file}'\n",
    "    print(f'Executing: {command}')\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "print('All operations completed successfully.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
